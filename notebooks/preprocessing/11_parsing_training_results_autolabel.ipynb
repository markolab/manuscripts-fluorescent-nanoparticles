{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf449c-18e7-4dcc-a194-9de011757c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21dda251-212b-4183-a2bb-c614d92d05c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import toml\n",
    "import pandas as pd\n",
    "import natsort\n",
    "import sleap\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import delayed, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d5fc45-35ab-461c-918b-6966d0277daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nested_value(data, key_string, delimiter='.'):\n",
    "    \"\"\"\n",
    "    Accesses a value in a nested dictionary using a string key.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The nested dictionary.\n",
    "        key_string (str): The string representing the path to the value.\n",
    "        delimiter (str, optional): The delimiter separating keys in the string. Defaults to '.'.\n",
    "\n",
    "    Returns:\n",
    "        The value at the specified path, or None if the path is invalid.\n",
    "    \"\"\"\n",
    "    keys = key_string.split(delimiter)\n",
    "    current = data\n",
    "    for key in keys:\n",
    "        if isinstance(current, dict) and key in current:\n",
    "            current = current[key]\n",
    "        else:\n",
    "            return None\n",
    "    return current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef1d3ae-b688-4c60-bdb0-a9aad4e7ca1b",
   "metadata": {},
   "source": [
    "# Parse grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53afbee-357b-4b5f-b1c4-39f0dfbf573b",
   "metadata": {},
   "source": [
    "1. TODO: need to check mAP test/train to see how robust learning is\n",
    "2. TODO: match 1 with overall performance (maybe equal weighting after normalize?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1984ba12-0ede-44b9-81d7-082397e72445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/storage/home/hcoda1/4/jmarkowitz30/shared_folder/active_lab_members/markowitz_jeffrey/active_projects/\"\n",
    "gridsearch_dir = [\n",
    "    # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras_kneejoints\"),\n",
    "    # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_same_camera_kneejoints\"),\n",
    "    # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera_kneejoints\"),\n",
    "    # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras\"),\n",
    "    # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_same_camera\"),\n",
    "    os.path.join(\n",
    "        root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras_v3\"\n",
    "    ),\n",
    "    os.path.join(\n",
    "        root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera_v3\"\n",
    "    ),\n",
    "    os.path.join(\n",
    "        root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_same_camera_v3\"\n",
    "    ),\n",
    "    os.path.join(\n",
    "        root_dir,\n",
    "        \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_same_camera_kneejoints_v3\",\n",
    "    ),\n",
    "    os.path.join(\n",
    "        root_dir,\n",
    "        \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras_kneejoints_v3\",\n",
    "    ),\n",
    "    os.path.join(\n",
    "        root_dir,\n",
    "        \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera_kneejoints_v3\",\n",
    "    ),\n",
    "    # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera\"),\n",
    "    # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras_large_models\"),\n",
    "]\n",
    "\n",
    "# gridsearch_dir = [\n",
    "#     os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_parameter_sweep\"),\n",
    "#     # os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_fluo_aligned_param_sweep_v2\"),\n",
    "# ]\n",
    "\n",
    "training_configs_fnames = []\n",
    "for _dir in gridsearch_dir:\n",
    "    training_configs_fnames += glob.glob(os.path.join(_dir, \"**/initial_config.json\"), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f526bd0b-243b-4c9b-b31b-e105c3f3cd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_configs_fnames = natsort.natsorted(training_configs_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6611fdad-fd16-449c-aa97-eac6cc144bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_fnames = {\n",
    "    \"val\": \"metrics.val.npz\",\n",
    "    \"train\": \"metrics.train.npz\",\n",
    "    \"test\": \"metrics.test.npz\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f83f07-4127-43fd-bf17-302516fc1059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_keynames = {\n",
    "    \"val\": \"validation\",\n",
    "    \"train\": \"training\",\n",
    "    \"test\": \"test\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b60c7b3-3f18-4916-85a2-5a14295ce74e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_list = [\n",
    "    \"dist.p50\",\n",
    "    \"dist.p90\",\n",
    "    \"dist.p99\",\n",
    "    \"dist.avg\",\n",
    "    \"vis.precision\",\n",
    "    \"vis.recall\",\n",
    "    \"oks_voc.mAP\",\n",
    "    \"oks_voc.mAR\",\n",
    "    \"pck.mPCK\",\n",
    "    \"pck.pcks.10\",\n",
    "    # \"pck.thresholds\",\n",
    "    \"oks.mOKS\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbf0c32-2a22-49b3-904e-dd17fa074f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(training_configs_fnames[0], \"r\") as f:\n",
    "    training_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50032486-6874-4736-883a-112e7fbeeb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_params = {\n",
    "    \"head_output_stride\": \"model.heads.single_instance.output_stride\",\n",
    "    \"head_sigma\": \"model.heads.single_instance.sigma\",\n",
    "    \"backbone_output_stride\": \"model.backbone.unet.output_stride\",\n",
    "    \"backbone_filters\": \"model.backbone.unet.filters\",\n",
    "    \"backbone_filters_rate\": \"model.backbone.unet.filters_rate\",\n",
    "    \"backbone_max_stride\": \"model.backbone.unet.max_stride\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9afc3640-43fb-4a78-ab56-b52dfc4aa412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_dir = os.path.dirname(training_configs_fnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fa5177-ff36-417f-bc8f-4fd892e7ba6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(\n",
    "    config_fname,\n",
    "    metrics_fnames=metrics_fnames,\n",
    "    label_keynames=label_keynames,\n",
    "    metric_list=metric_list,\n",
    "    save_params=save_params,\n",
    "    node_names=None,\n",
    "):\n",
    "    param_dct = {}\n",
    "    metrics = {}\n",
    "    use_dir = os.path.dirname(config_fname)\n",
    "    param_dir = os.path.basename(use_dir)\n",
    "\n",
    "    if node_names is None:\n",
    "        slp_data = sleap.load_file(os.path.join(use_dir, \"labels_gt.val.slp\"))\n",
    "        node_names = [_.name for _ in slp_data.skeletons[0].nodes]\n",
    "\n",
    "    if (\"hindleg\" in config_fname) or (\"joint\" in config_fname):\n",
    "        try:\n",
    "            metrics = {}\n",
    "            for k, v in metrics_fnames.items():\n",
    "                tmp_gt = sleap.load_file(\n",
    "                    os.path.join(use_dir, v.replace(\"metrics.\", \"labels_gt.\").replace(\"npz\", \"slp\"))\n",
    "                )\n",
    "                tmp_pr = sleap.load_file(\n",
    "                    os.path.join(use_dir, v.replace(\"metrics.\", \"labels_pr.\").replace(\"npz\", \"slp\"))\n",
    "                )\n",
    "                metrics[k] = sleap.nn.evals.evaluate(tmp_gt, tmp_pr, oks_scale=150, user_labels_only=True)\n",
    "        except (IndexError, FileNotFoundError) as e:\n",
    "            print(e)\n",
    "            return None\n",
    "    else:\n",
    "        try:\n",
    "            metrics = {}\n",
    "            for k, v in metrics_fnames.items():\n",
    "                metrics[k] = sleap.load_metrics(os.path.join(use_dir, v))\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    with open(config_fname, \"r\") as f:\n",
    "        initial_config = json.load(f)\n",
    "\n",
    "    with open(os.path.join(use_dir, \"training_config.json\"), \"r\") as f:\n",
    "        training_config = json.load(f)\n",
    "\n",
    "    nframes = {}\n",
    "    for k, v in label_keynames.items():\n",
    "        nframes[k] = len(training_config[\"data\"][\"labels\"][f\"{v}_inds\"])\n",
    "\n",
    "    for _metric in metric_list:\n",
    "        for _metric_type, _metric_data in metrics.items():\n",
    "            if \"pcks\" in _metric:\n",
    "                # find where threshold is number, pull out that pck\n",
    "                use_name = \".\".join(_metric.split(\".\")[:2])\n",
    "                use_threshold = float(_metric.split(\".\")[-1])\n",
    "                use_idx = np.flatnonzero(_metric_data[\"pck.thresholds\"] == use_threshold)\n",
    "                try:\n",
    "                    param_dct[f\"{_metric_type}_{_metric}\"] = np.nanmean(_metric_data[use_name][:, use_idx, :])\n",
    "                except IndexError:\n",
    "                    pass\n",
    "            else:\n",
    "                param_dct[f\"{_metric_type}_{_metric}\"] = np.nanmean(_metric_data[_metric])\n",
    "\n",
    "    # get kpoint specific here...\n",
    "    for _metric_type, _metric_data in metrics.items():\n",
    "        kpoint_dist = np.nanmean(_metric_data[\"dist.dists\"], axis=0)\n",
    "        # now break out by node names\n",
    "        for _dist, _node in zip(kpoint_dist, node_names):\n",
    "            param_dct[f\"{_metric_type}_dist.parts.{_node}\"] = _dist\n",
    "    param_dct[\"basename\"] = os.path.basename(os.path.dirname(config_fname))\n",
    "    param_dct[\"condition\"] = \"all\"\n",
    "    param_dct[\"filename\"] = config_fname\n",
    "\n",
    "    for k, v in save_params.items():\n",
    "        param_dct[k] = get_nested_value(initial_config, v)\n",
    "\n",
    "    if \"same_camera\" in config_fname:\n",
    "        param_dct[\"condition\"] = \"same\"\n",
    "    elif \"heldout_camera\" in config_fname:\n",
    "        param_dct[\"condition\"] = \"different\"\n",
    "    param_dct[\"is_joint\"] = \"kneejoints\" in config_fname\n",
    "    for k, v in nframes.items():\n",
    "        param_dct[f\"nframes_{k}\"] = v\n",
    "    return param_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2747ce-61f5-494e-a5dd-3a8c09971fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = toml.load(\"../preprocessing/config.toml\")\n",
    "save_file = os.path.join(config[\"dirs\"][\"analysis\"], \"sleap_metrics_qd_training.parquet\")\n",
    "force = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9dcee2e-5cc6-47aa-916e-6ed708acab60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=15)]: Done  31 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=15)]: Done  42 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=15)]: Done  55 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=15)]: Done  68 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=15)]: Done  83 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=15)]: Done  98 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=15)]: Done 115 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=15)]: Done 132 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=15)]: Done 151 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=15)]: Done 170 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=15)]: Done 191 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=15)]: Done 212 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=15)]: Done 235 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=15)]: Done 264 out of 266 | elapsed:   32.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=15)]: Done 266 out of 266 | elapsed:   35.7s finished\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(save_file) or force:\n",
    "    delays = []\n",
    "    for _config_fname in training_configs_fnames:\n",
    "        delays.append(delayed(get_metrics)(_config_fname))\n",
    "\n",
    "    results = Parallel(n_jobs=15, backend=\"loky\", verbose=10)(delays)\n",
    "    df = pd.DataFrame([_result for _result in results if _result is not None])\n",
    "    convert_cols = df.filter(regex=\"(recall|precision)\").columns\n",
    "    df[convert_cols] = df[convert_cols].astype(\"float\")\n",
    "    df.to_parquet(save_file)\n",
    "else:\n",
    "    df = pd.read_parquet(save_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
