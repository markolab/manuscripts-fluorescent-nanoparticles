{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf449c-18e7-4dcc-a194-9de011757c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b8cf6f-95cf-4b04-af4d-a19fbc22bbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import toml\n",
    "import glob\n",
    "import joblib\n",
    "import h5py\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from markovids import vid\n",
    "from qd_analysis.util import clean_df\n",
    "from scipy import signal\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdc7c55-8b45-4a9a-b34c-0933260b578a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmentation_dir = \"_segmentation_tau-0-pretrain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f62dc534-6b1a-4fa9-91c9-30a7e6299ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_lags\": 200,\n",
    "    \"spacing\": 250,\n",
    "    \"force\": True,\n",
    "    \"mask_non_mouse_pixels\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6af78-dd92-4b5f-a533-a31359064f6a",
   "metadata": {},
   "source": [
    "## User functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592119f7-f923-45ce-8ade-21979df3b079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_spatial_autocorr(\n",
    "    dat_file,\n",
    "    spacing=200,\n",
    "    # n_surrogates=25,\n",
    "    reader_kwargs={\"threads\": 2},\n",
    "    distortion_coeffs=None,\n",
    "    intrinsic_matrix=None,\n",
    "    segmentation_dir=segmentation_dir,\n",
    "    bground_dir=\"_bground\",\n",
    "    output_dir=\"_autocorr\",\n",
    "    force=False,\n",
    "    mask_non_mouse_pixels=False,\n",
    "    max_lags=100,\n",
    "):\n",
    "    metadata = toml.load(os.path.join(os.path.dirname(dat_file), \"../metadata.toml\"))\n",
    "    dirname, fname_reflectance = os.path.split(dat_file.replace(\"fluorescence\", \"reflectance\"))\n",
    "\n",
    "    fname_reflectance = os.path.splitext(os.path.basename(fname_reflectance))[0]\n",
    "    fname_fluorescence = os.path.splitext(os.path.basename(dat_file))[0]\n",
    "    cam_name = fname_reflectance.replace(\"-reflectance\", \"\")\n",
    "\n",
    "    save_file = os.path.join(dirname, output_dir, f\"{cam_name}_autocorr-data.pkl\")\n",
    "    if os.path.exists(save_file) and not force:\n",
    "        try:\n",
    "            results = joblib.load(save_file)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    if segmentation_dir is not None:\n",
    "        segmentation_path = os.path.join(dirname, segmentation_dir, f\"{fname_reflectance}.hdf5\")\n",
    "    else:\n",
    "        segmentation_path = None\n",
    "\n",
    "    bground_path = os.path.join(dirname, bground_dir, f\"{fname_fluorescence}.hdf5\")\n",
    "    # save_file = os.path.join(dirname, output_dir, f\"{fname_fluorescence}.parquet\")\n",
    "\n",
    "    os.makedirs(os.path.join(dirname, output_dir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dirname, bground_dir), exist_ok=True)\n",
    "\n",
    "    reader = vid.io.AutoReader(\n",
    "        dat_file,\n",
    "        **reader_kwargs,\n",
    "    )\n",
    "    frame_range = range(0, reader.nframes, spacing)\n",
    "    # print(len(list(frame_range)))\n",
    "\n",
    "    if (segmentation_path is not None) and os.path.exists(segmentation_path):\n",
    "        with h5py.File(segmentation_path) as f:\n",
    "            masks = f[\"labels\"][frame_range]\n",
    "            masks = masks.astype(\"uint8\")\n",
    "    elif mask_non_mouse_pixels:\n",
    "        warnings.warn(f\"No mask found {dat_file}\")\n",
    "        reader.close()\n",
    "        return None\n",
    "    elif not mask_non_mouse_pixels:\n",
    "        # if we're not masking skip...\n",
    "        pass\n",
    "\n",
    "    if os.path.exists(bground_path):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            with h5py.File(bground_path, \"r\") as f:\n",
    "                rolling_bgrounds = f[\"bground\"][()]\n",
    "                idxs = f[\"frame_idxs\"][()]\n",
    "            frames = reader.get_frames(frame_range)\n",
    "            # frames = reader.undistort_frames(frames)\n",
    "    else:\n",
    "        warnings.warn(f\"No bground found {dat_file}\")\n",
    "        reader.close()\n",
    "        return None\n",
    "\n",
    "    bground_sub = np.zeros(frames.shape, dtype=\"int16\")\n",
    "    for i, (_idx, _frame) in enumerate(zip(frame_range, frames)):\n",
    "        use_bground = np.argmin(np.abs(idxs - _idx))\n",
    "        bground_sub[i] = np.clip(_frame - rolling_bgrounds[use_bground], 0, 255)\n",
    "        if mask_non_mouse_pixels:\n",
    "            bground_sub[i][masks[i] <= 0] = 0  # mask out non-mouse stuff... # DO WE NEED THIS???\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if intrinsic_matrix is not None:\n",
    "        for i in range(len(bground_sub)):\n",
    "            bground_sub[i] = cv2.undistort(bground_sub[i], intrinsic_matrix, distortion_coeffs)\n",
    "\n",
    "    corrs = []\n",
    "    raw_corrs = []\n",
    "    for i in range(len(bground_sub)):\n",
    "        corr_frame = bground_sub[i].astype(\"float32\").copy()\n",
    "        corr_frame -= corr_frame.mean()\n",
    "        _corr = signal.fftconvolve(corr_frame, corr_frame[::-1, ::-1], mode=\"full\")\n",
    "        sz = _corr.shape\n",
    "        my, mx = sz[0] // 2, sz[1] // 2\n",
    "        _corr_norm = _corr / (corr_frame.size * np.var(corr_frame))\n",
    "        corrs.append(_corr_norm[my - max_lags : my + max_lags][:, mx - max_lags : mx + max_lags])\n",
    "        raw_corrs.append(_corr[my - max_lags : my + max_lags][:, mx - max_lags : mx + max_lags])\n",
    "\n",
    "    ave_corr = np.mean(corrs, axis=0)\n",
    "    ave_raw_corr = np.mean(raw_corrs, axis=0)\n",
    "    nframes, height, width = bground_sub.shape\n",
    "\n",
    "    results = {\n",
    "        \"ave_corr\": ave_corr,\n",
    "        \"ave_raw_corr\": ave_raw_corr,\n",
    "        \"intrinsic_matrix\": intrinsic_matrix,\n",
    "        \"distortion_coeffs\": distortion_coeffs,\n",
    "        \"start_time\": metadata[\"start_time\"],\n",
    "        \"filename\": dat_file,\n",
    "        \"max_lags\": max_lags,\n",
    "        \"im_size\": bground_sub[0].size,\n",
    "        \"im_shape\": bground_sub[0].shape,\n",
    "    }\n",
    "    for k, v in metadata[\"user_input\"].items():\n",
    "        results[k] = v\n",
    "    joblib.dump(results, save_file)\n",
    "    return results\n",
    "    # return bground_sub, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e2ce6-b8f0-4d26-a151-cd0f1dd38f84",
   "metadata": {},
   "source": [
    "# Quantify fluorescence length-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e30d50-fdec-4623-bcff-3056ec18d4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/storage/home/hcoda1/4/jmarkowitz30/shared_folder/active_lab_members/markowitz_jeffrey/active_projects/quantum_dots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ffd27b-4c9e-4c91-bd46-6cdc798e33bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(root_dir, \"timecourse_01\")\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "\n",
    "base_dir = os.path.join(root_dir, \"timecourse_01_agarose_beads\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfdade37-3901-4871-bf34-c8ef6b3e0f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calibration_data = toml.load(os.path.join(root_dir, \"timecourse_01_calibration.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b945e7-e8fd-42de-9e02-61b10692f509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dc70e82ab34026ae44dbd56f5809ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get subject names and filter that stuff...\n",
    "metadata = {}\n",
    "for _file in tqdm(fluo_files):\n",
    "    metadata[_file] = toml.load(os.path.join(os.path.dirname(_file), \"../metadata.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c5fc09a-9fe2-4cdf-9ae8-d511dd8568c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=18)]: Using backend MultiprocessingBackend with 18 concurrent workers.\n",
      "[Parallel(n_jobs=18)]: Done   5 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=18)]: Done  14 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=18)]: Done  25 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=18)]: Done  36 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=18)]: Done  49 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=18)]: Done  62 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=18)]: Done  77 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=18)]: Done  92 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=18)]: Done 109 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=18)]: Done 126 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=18)]: Done 145 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=18)]: Done 164 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=18)]: Done 185 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=18)]: Done 206 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=18)]: Done 229 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=18)]: Done 252 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=18)]: Done 277 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=18)]: Done 302 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=18)]: Done 329 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=18)]: Done 356 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=18)]: Done 385 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=18)]: Done 414 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=18)]: Done 445 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=18)]: Done 476 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=18)]: Done 509 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=18)]: Done 542 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=18)]: Done 577 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=18)]: Done 612 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=18)]: Done 649 tasks      | elapsed: 27.2min\n",
      "[Parallel(n_jobs=18)]: Done 686 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=18)]: Done 725 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=18)]: Done 780 out of 780 | elapsed: 32.7min finished\n"
     ]
    }
   ],
   "source": [
    "delays = []\n",
    "for _file in fluo_files:\n",
    "    cam = os.path.basename(_file).replace(\"-fluorescence.avi\", \"\")\n",
    "    delays.append(\n",
    "        delayed(get_spatial_autocorr)(\n",
    "            _file,\n",
    "            intrinsic_matrix=np.array(calibration_data[\"intrinsics\"][cam]),\n",
    "            distortion_coeffs=np.array(calibration_data[\"distortion_coeffs\"][cam]),\n",
    "            **params,\n",
    "        )\n",
    "    )\n",
    "print(len(delays))\n",
    "dat = Parallel(n_jobs=18, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d26d27-cb04-4f1f-8363-aa9fccc17ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(root_dir, \"timecourse_02\")\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "\n",
    "base_dir = os.path.join(root_dir, \"timecourse_02_joints\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "\n",
    "base_dir = os.path.join(root_dir, \"timecourse_03\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4840794-90ba-4565-99c1-76d16105290c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calibration_data = [toml.load(os.path.join(root_dir, \"timecourse_02_calibration_v1.toml\")),\n",
    "                    toml.load(os.path.join(root_dir, \"timecourse_02_calibration_v2.toml\")),\n",
    "                    toml.load(os.path.join(root_dir, \"timecourse_04_calibration.toml\")),\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85cfe23e-4bf5-4457-88a2-05713281e49d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5f86e3e7f6403e8edf7454b4b5a3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get subject names and filter that stuff...\n",
    "metadata = {}\n",
    "for _file in tqdm(fluo_files):\n",
    "    metadata[_file] = toml.load(os.path.join(os.path.dirname(_file), \"../metadata.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "665a258c-adbc-474c-b802-06e8b3dff792",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend MultiprocessingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=15)]: Done  31 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=15)]: Done  42 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=15)]: Done  55 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=15)]: Done  68 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=15)]: Done  83 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=15)]: Done  98 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=15)]: Done 115 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=15)]: Done 132 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=15)]: Done 151 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=15)]: Done 170 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=15)]: Done 191 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=15)]: Done 212 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=15)]: Done 235 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=15)]: Done 258 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=15)]: Done 283 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=15)]: Done 308 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=15)]: Done 335 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=15)]: Done 362 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=15)]: Done 391 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=15)]: Done 420 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=15)]: Done 451 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=15)]: Done 482 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=15)]: Done 515 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=15)]: Done 548 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=15)]: Done 601 out of 601 | elapsed: 18.6min finished\n"
     ]
    }
   ],
   "source": [
    "delays = []\n",
    "for _file in fluo_files:\n",
    "    cam = os.path.basename(_file).replace(\"-fluorescence.avi\", \"\")\n",
    "    timestamp = pd.to_datetime(metadata[_file][\"start_time\"])\n",
    "    if timestamp.floor(\"d\") > pd.to_datetime(\"2024-11-10\"):\n",
    "        use_calibration_data = calibration_data[2]\n",
    "    elif timestamp.floor(\"d\") > pd.to_datetime(\"2024-06-10\"):\n",
    "        use_calibration_data = calibration_data[1]\n",
    "    else:\n",
    "        use_calibration_data = calibration_data[0]\n",
    "    # for 0610 load v1 after that load v2 calibration data...\n",
    "    if cam not in use_calibration_data[\"intrinsics\"].keys():\n",
    "        warnings.warn(f\"{_file} uses {cam} which is not in intrinsics\")\n",
    "        continue\n",
    "    delays.append(\n",
    "        delayed(get_spatial_autocorr)(\n",
    "            _file,\n",
    "            intrinsic_matrix=np.array(use_calibration_data[\"intrinsics\"][cam]),\n",
    "            distortion_coeffs=np.array(use_calibration_data[\"distortion_coeffs\"][cam]),\n",
    "            **params,\n",
    "        )\n",
    "    )\n",
    "print(len(delays))\n",
    "dat2 = Parallel(n_jobs=15, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44f74410-f312-4540-91cd-61464b63bf6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat += dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f725ccd4-da71-44da-bfcb-cbcb8eab1ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(root_dir, \"sciadv_rebuttal/dilution_series\")\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "\n",
    "# note that even if we crop, we're cropping from the BOTTOM and the RIGHT so no need to adjust intrinsics\n",
    "# we only adjust cx and cy if we crop from TOP or LEFT\n",
    "base_dir = os.path.join(root_dir, \"sciadv_rebuttal/exposure_series\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2857f487-91f2-48e4-8bb5-83838a0804da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7017e2197aa149268045ce5a376fe420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get subject names and filter that stuff...\n",
    "metadata = {}\n",
    "for _file in tqdm(fluo_files):\n",
    "    metadata[_file] = toml.load(os.path.join(os.path.dirname(_file), \"../metadata.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3473ac1-4010-43f1-b291-b7e72a7d45f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend MultiprocessingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=15)]: Done  31 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=15)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=15)]: Done  55 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=15)]: Done  68 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=15)]: Done  83 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=15)]: Done  98 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=15)]: Done 123 out of 138 | elapsed:  3.1min remaining:   22.6s\n",
      "[Parallel(n_jobs=15)]: Done 138 out of 138 | elapsed:  3.4min finished\n"
     ]
    }
   ],
   "source": [
    "delays = []\n",
    "for _file in fluo_files:\n",
    "    cam = os.path.basename(_file).replace(\"-fluorescence.avi\", \"\")\n",
    "    timestamp = pd.to_datetime(metadata[_file][\"start_time\"])\n",
    "    if timestamp.floor(\"d\") > pd.to_datetime(\"2024-11-10\"):\n",
    "        use_calibration_data = calibration_data[2]\n",
    "    elif timestamp.floor(\"d\") > pd.to_datetime(\"2024-06-10\"):\n",
    "        use_calibration_data = calibration_data[1]\n",
    "    else:\n",
    "        use_calibration_data = calibration_data[0]\n",
    "    delays.append(\n",
    "        delayed(get_spatial_autocorr)(\n",
    "            _file,\n",
    "            intrinsic_matrix=np.array(use_calibration_data[\"intrinsics\"][cam]),\n",
    "            distortion_coeffs=np.array(use_calibration_data[\"distortion_coeffs\"][cam]),\n",
    "            **params,\n",
    "        )\n",
    "    )\n",
    "print(len(delays))\n",
    "dat3 = Parallel(n_jobs=15, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86713fe2-cf5f-4eff-b617-a49826661ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = dat + dat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc8d225f-2e58-4ef7-9a30-a3eeea841cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_dat = [_dat for _dat in dat if _dat is not None]\n",
    "corr_df = pd.DataFrame(use_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2c80d5d-41e2-46d4-8601-934a9737560c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b71014c4-7704-452b-8c4c-fb3587869840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_df = clean_df(\n",
    "    corr_df,\n",
    "    exp_types=config[\"aliases\"],\n",
    "    subject_typos=config[\"typos\"][\"subject\"],\n",
    "    chk_fields=config[\"parse_metadata\"][\"chk_fields\"],\n",
    "    exclude_subjects=config[\"exclusions\"][\"subjects\"],\n",
    "    exclude_dates=config[\"exclusions\"][\"dates\"],\n",
    "    exclude_pairs=config[\"exclusions\"][\"pairs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa576d1a-d0fc-4824-bbf0-497dbcd2d5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# convert it!\n",
    "\n",
    "corr_df[\"distortion_coeffs\"] = pa.array(corr_df[\"distortion_coeffs\"].apply(lambda x: x.squeeze()))\n",
    "corr_df[\"ave_corr\"] = pa.array(corr_df[\"ave_corr\"].apply(list))\n",
    "corr_df[\"ave_raw_corr\"] = pa.array(corr_df[\"ave_raw_corr\"].apply(list))\n",
    "\n",
    "# corr_df[\"max_surrogate\"] = pa.array(corr_df[\"max_surrogate\"].apply(list))\n",
    "corr_df[\"intrinsic_matrix\"] = pa.array(corr_df[\"intrinsic_matrix\"].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "410e22d7-486b-4777-8ddd-ec1be9cf7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cameras = list(toml.load(os.path.join(root_dir, \"timecourse_01_calibration.toml\"))[\"distortion_coeffs\"].keys())\n",
    "corr_df = corr_df.query(\"camera.isin(@use_cameras)\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b153e07c-336a-48ff-8f32-1450d97e1d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(config[\"dirs\"][\"analysis\"], exist_ok=True)\n",
    "corr_df.to_parquet(os.path.join(config[\"dirs\"][\"analysis\"], \"fluorescence_autocorrelation.parquet\"), engine=\"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
