{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf449c-18e7-4dcc-a194-9de011757c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4946f687-63c7-460a-8fba-7a77f6d1d2aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import toml\n",
    "import glob\n",
    "import h5py\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from markovids import vid\n",
    "from qd_analysis.util import clean_df\n",
    "from scipy import signal\n",
    "from skimage.measure import regionprops_table\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdc7c55-8b45-4a9a-b34c-0933260b578a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmentation_dir = \"_segmentation_tau-0-pretrain\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6af78-dd92-4b5f-a533-a31359064f6a",
   "metadata": {},
   "source": [
    "## User functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c827cfd3-aa33-4793-806e-1933711dd14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sos_filter(x, fps, tau=0.01, order=3):\n",
    "    sos = signal.butter(order, (1 / tau) / (fps / 2), btype=\"low\", output=\"sos\")\n",
    "    return signal.sosfiltfilt(sos, x, axis=0)\n",
    "\n",
    "\n",
    "def lp_filter(x, sigma):\n",
    "    return cv2.GaussianBlur(x, [0, 0], sigma, sigma)\n",
    "\n",
    "\n",
    "def bp_filter(x, sigma1, sigma2, clip=True):\n",
    "    if (sigma2 == 0) or (sigma2 is None):\n",
    "        return lp_filter(x, sigma1)\n",
    "    else:\n",
    "        return np.clip(\n",
    "            lp_filter(x, sigma1) - lp_filter(x, sigma2),\n",
    "            0 if clip == True else -np.inf,\n",
    "            np.inf,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592119f7-f923-45ce-8ade-21979df3b079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_average_intensity(\n",
    "    dat_file,\n",
    "    spacing=400,\n",
    "    reader_kwargs={\"threads\": 2},\n",
    "    segmentation_dir=segmentation_dir,\n",
    "    distortion_coeffs=None,\n",
    "    intrinsic_matrix=None,\n",
    "    bground_dir=\"_bground\",\n",
    "    output_dir=\"_ave_intensity\",\n",
    "    summary_quantiles=[0.99, 0.999, 1.0],\n",
    "    bpass=(1, 3),\n",
    "    force=False,\n",
    "):\n",
    "    # ONLY undistort at the end so we don't have to account for it\n",
    "    # when we don't need it (e.g. keypoints)\n",
    "    metadata = toml.load(os.path.join(os.path.dirname(dat_file), \"../metadata.toml\"))\n",
    "    dirname, fname_reflectance = os.path.split(dat_file.replace(\"fluorescence\", \"reflectance\"))\n",
    "    fname_reflectance, ext = os.path.splitext(fname_reflectance)\n",
    "    fname_fluorescence, ext = os.path.splitext(os.path.basename(dat_file))\n",
    "\n",
    "    segmentation_path = os.path.join(dirname, segmentation_dir, f\"{fname_reflectance}.hdf5\")\n",
    "    bground_path = os.path.join(dirname, bground_dir, f\"{fname_fluorescence}.hdf5\")\n",
    "    save_file = os.path.join(dirname, output_dir, f\"{fname_fluorescence}.parquet\")\n",
    "\n",
    "    os.makedirs(os.path.join(dirname, output_dir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dirname, bground_dir), exist_ok=True)\n",
    "\n",
    "    if os.path.exists(save_file) and not force:\n",
    "        stats = pd.read_parquet(save_file)\n",
    "        return stats\n",
    "\n",
    "    reader = vid.io.AutoReader(\n",
    "        dat_file,\n",
    "        **reader_kwargs,\n",
    "    )\n",
    "    frame_range = range(0, reader.nframes, spacing)\n",
    "\n",
    "    if os.path.exists(segmentation_path):\n",
    "        try:\n",
    "            with h5py.File(segmentation_path) as f:\n",
    "                masks = f[\"labels\"][frame_range]\n",
    "                masks = masks.astype(\"uint8\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            warnings.warn(f\"Could not load mask from {segmentation_path}\")\n",
    "            reader.close()\n",
    "            return None\n",
    "    else:\n",
    "        warnings.warn(f\"No mask found {segmentation_path} for {dat_file}\")\n",
    "        reader.close()\n",
    "        masks = None\n",
    "        # return None\n",
    "\n",
    "    if os.path.exists(bground_path):\n",
    "        with warnings.catch_warnings():\n",
    "            with h5py.File(bground_path, \"r\") as f:\n",
    "                rolling_bgrounds = f[\"bground\"][()]\n",
    "                idxs = f[\"frame_idxs\"][()]\n",
    "            frames = reader.get_frames(frame_range)\n",
    "    else:\n",
    "        warnings.warn(f\"No background found {dat_file}\")\n",
    "        reader.close()\n",
    "        return None\n",
    "\n",
    "    bground_sub = np.zeros(frames.shape, dtype=\"int16\")\n",
    "    for i, (_idx, _frame) in enumerate(zip(frame_range, frames)):\n",
    "        use_bground = np.argmin(np.abs(idxs - _idx))\n",
    "        bground_sub[i] = np.clip(_frame - rolling_bgrounds[use_bground], 0, 255)\n",
    "\n",
    "    bground_sub_raw = bground_sub.copy()\n",
    "    for i in range(len(bground_sub)):\n",
    "        bground_sub[i] = bp_filter(bground_sub[i], *bpass)\n",
    "\n",
    "    if intrinsic_matrix is not None:\n",
    "        if masks is not None:\n",
    "            for i in range(len(masks)):\n",
    "                masks[i] = cv2.undistort(masks[i], intrinsic_matrix, distortion_coeffs)\n",
    "        for i in range(len(bground_sub)):\n",
    "            bground_sub[i] = cv2.undistort(bground_sub[i], intrinsic_matrix, distortion_coeffs)\n",
    "        for i in range(len(bground_sub_raw)):\n",
    "            bground_sub_raw[i] = cv2.undistort(bground_sub_raw[i], intrinsic_matrix, distortion_coeffs)\n",
    "\n",
    "    if masks is not None:\n",
    "\n",
    "        extra_props = []\n",
    "        for _quantile in summary_quantiles:\n",
    "            func = lambda regionmask, im, quantile=_quantile: np.quantile(im[regionmask], quantile)\n",
    "            func.__name__ = f\"q{_quantile}\"\n",
    "            extra_props.append(func)\n",
    "\n",
    "        func = lambda regionmask, im: np.std(im[regionmask])\n",
    "        func.__name__ = \"std\"\n",
    "        extra_props.append(func)\n",
    "\n",
    "        bground_mu = bground_sub[masks == 0].mean()\n",
    "        bground_sig = bground_sub[masks == 0].std()\n",
    "\n",
    "        func = lambda regionmask, im: np.mean((im[regionmask] > (bground_mu + 10 * bground_sig)).astype(\"float32\"))\n",
    "        func.__name__ = \"frac_pixels_above_background\"\n",
    "        extra_props.append(func)\n",
    "\n",
    "        stats = [\n",
    "            regionprops_table(\n",
    "                _mask,\n",
    "                intensity_image=_im,\n",
    "                properties=[\"mean_intensity\"],\n",
    "                extra_properties=extra_props,\n",
    "            )\n",
    "            for _im, _mask in zip(bground_sub, masks)\n",
    "        ]\n",
    "\n",
    "        dfs = []\n",
    "        use_idx = []\n",
    "        for i, (_stat, _idx) in enumerate(zip(stats, frame_range)):\n",
    "            _df = pd.DataFrame(_stat)\n",
    "            if _df.empty:\n",
    "                continue\n",
    "            _df[\"frame_idx\"] = _idx\n",
    "            dfs.append(_df)\n",
    "            use_idx.append(i)\n",
    "        use_idx = np.array(use_idx).astype(\"int\")\n",
    "        stats = pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        use_idx = np.arange(len(frames)).astype(\"int\")\n",
    "        stats = pd.DataFrame()\n",
    "\n",
    "    for _quantile in summary_quantiles:\n",
    "        _tmp = np.quantile(bground_sub_raw[use_idx], _quantile, axis=(1, 2))\n",
    "        stats[f\"q{_quantile}_fullframe_raw\"] = _tmp\n",
    "    stats[\"mean_intensity_fullframe_raw\"] = np.mean(bground_sub_raw[use_idx], axis=(1, 2))\n",
    "    stats[\"std_intensity_fullframe_raw\"] = np.std(bground_sub_raw[use_idx], axis=(1, 2))\n",
    "\n",
    "    for _quantile in summary_quantiles:\n",
    "        _tmp = np.quantile(bground_sub[use_idx], _quantile, axis=(1, 2))\n",
    "        stats[f\"q{_quantile}_fullframe_bpass\"] = _tmp\n",
    "    stats[\"mean_intensity_fullframe_bpass\"] = np.mean(bground_sub[use_idx], axis=(1, 2))\n",
    "    stats[\"std_intensity_fullframe_bpass\"] = np.std(bground_sub[use_idx], axis=(1, 2))\n",
    "\n",
    "    stats[\"start_time\"] = metadata[\"start_time\"]\n",
    "    stats[\"hw_trigger_pulse_width\"] = str(metadata[\"cli_parameters\"][\"hw_trigger_pulse_width\"])\n",
    "    stats[\"filename\"] = dat_file\n",
    "    for k, v in metadata[\"user_input\"].items():\n",
    "        stats[k] = v\n",
    "\n",
    "    stats.to_parquet(save_file)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e2ce6-b8f0-4d26-a151-cd0f1dd38f84",
   "metadata": {},
   "source": [
    "# Quantify fluorescence decay over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249093aa-8bcc-4cbc-aaef-022b73885f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to use different calibration files for different days..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e028da-e051-4adf-8f40-1d8febfdbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.expanduser(\"~/shared_folder/active_lab_members/markowitz_jeffrey/active_projects/quantum_dots/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dbc4d25-2494-4342-9488-1d44ecad7b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(root_dir, \"timecourse_01\")\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = os.path.join(root_dir, \"timecourse_01_agarose_beads\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044bc3c9-798d-4926-b335-677f32868e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = toml.load(os.path.join(root_dir, \"timecourse_01_calibration.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e1beb2-31f7-49b9-a5ea-339473ad76a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbeea8903ec74c1d99395a3ec1b1c62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get subject names and filter that stuff...\n",
    "metadata = {}\n",
    "for _file in tqdm(fluo_files):\n",
    "    metadata[_file] = toml.load(os.path.join(os.path.dirname(_file), \"../metadata.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a788be6-0411-411e-a39e-f4203f3c4354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.08932232856750488s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.06818342208862305s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1283891201019287s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 662 out of 780 | elapsed:    2.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 780 out of 780 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "delays = []\n",
    "for _file in fluo_files:\n",
    "    cam = os.path.basename(_file).replace(\"-fluorescence.avi\", \"\")\n",
    "    delays.append(\n",
    "        delayed(get_average_intensity)(\n",
    "            _file,\n",
    "            force=False,\n",
    "            intrinsic_matrix=np.array(calibration_data[\"intrinsics\"][cam]),\n",
    "            distortion_coeffs=np.array(calibration_data[\"distortion_coeffs\"][cam])        \n",
    "        )\n",
    "    )\n",
    "print(len(delays))\n",
    "dat = Parallel(n_jobs=-1, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c87bec-14a9-46cb-82ec-51e98e6a65a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(root_dir, \"timecourse_02\")\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = os.path.join(root_dir, \"timecourse_02_joints\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = os.path.join(root_dir, \"timecourse_03\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = os.path.join(root_dir, \"sciadv_rebuttal/exposure_series\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = os.path.join(root_dir, \"sciadv_rebuttal/dilution_series\")\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61ede1da-7de1-49f0-a8d9-363752bd6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = [toml.load(os.path.join(root_dir, \"timecourse_02_calibration_v1.toml\")),\n",
    "                    toml.load(os.path.join(root_dir, \"timecourse_02_calibration_v2.toml\")),\n",
    "                    toml.load(os.path.join(root_dir, \"timecourse_04_calibration.toml\")),\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cbbb51a-894f-47d7-8415-cc98bf4fd58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea07e527ba5047e9b07921e26d433ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get subject names and filter that stuff...\n",
    "metadata = {}\n",
    "for _file in tqdm(fluo_files):\n",
    "    metadata[_file] = toml.load(os.path.join(os.path.dirname(_file), \"../metadata.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c032120-1e41-4816-9ca1-e43e47bea2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.058277130126953125s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.06664323806762695s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 220 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.032125059616554s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 364 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 503 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 542 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 565 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 588 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.18199327087200073s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 613 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 638 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.06923198699951172s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 678 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 700 out of 739 | elapsed:    7.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 739 out of 739 | elapsed:    7.7s finished\n"
     ]
    }
   ],
   "source": [
    "delays = []\n",
    "for _file in fluo_files:\n",
    "    cam = os.path.basename(_file).replace(\"-fluorescence.avi\", \"\")\n",
    "    timestamp = pd.to_datetime(metadata[_file][\"start_time\"])\n",
    "    if timestamp.floor(\"d\") > pd.to_datetime(\"2024-11-10\"):\n",
    "        use_calibration_data = calibration_data[2]\n",
    "    elif timestamp.floor(\"d\") > pd.to_datetime(\"2024-06-10\"):\n",
    "        use_calibration_data = calibration_data[1]\n",
    "    else:\n",
    "        use_calibration_data = calibration_data[0]\n",
    "    # for 0610 load v1 after that load v2 calibration data...\n",
    "    delays.append(\n",
    "        delayed(get_average_intensity)(\n",
    "            _file,\n",
    "            force=False,\n",
    "            intrinsic_matrix=np.array(use_calibration_data[\"intrinsics\"][cam]),\n",
    "            distortion_coeffs=np.array(use_calibration_data[\"distortion_coeffs\"][cam])        \n",
    "        )\n",
    "    )\n",
    "print(len(delays))\n",
    "dat2 = Parallel(n_jobs=-1, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea1407a2-50af-40ae-b6a9-826f20cf7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat += dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af0b32f-3021-4ba6-a3df-c6716cf716c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_df = pd.concat(dat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1295a1fd-7819-4210-9e2e-559e2e13d248",
   "metadata": {},
   "source": [
    "# clean up df and save off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3feb23b4-e5c4-4b3e-8278-b20c1828cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5cc0061-cf5a-4092-9909-6818cffdf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_df = clean_df(\n",
    "    fluo_df,\n",
    "    exp_types=config[\"aliases\"],\n",
    "    subject_typos=config[\"typos\"][\"subject\"],\n",
    "    chk_fields=config[\"parse_metadata\"][\"chk_fields\"],\n",
    "    exclude_subjects=config[\"exclusions\"][\"subjects\"],\n",
    "    exclude_dates=config[\"exclusions\"][\"dates\"],\n",
    "    exclude_pairs=config[\"exclusions\"][\"pairs\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "725d228a-35d5-43c5-8498-4220b26a2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cameras = list(toml.load(os.path.join(root_dir, \"timecourse_01_calibration.toml\"))[\"distortion_coeffs\"].keys())\n",
    "fluo_df = fluo_df.query(\"camera.isin(@use_cameras)\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db45dc4d-4904-417d-899b-5f6d7bf2bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config[\"dirs\"][\"analysis\"], exist_ok=True)\n",
    "fluo_df.to_parquet(os.path.join(config[\"dirs\"][\"analysis\"], \"fluorescence_intensity_over_time.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis (local)",
   "language": "python",
   "name": "data_analysis_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
