{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf449c-18e7-4dcc-a194-9de011757c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d48703e-16a6-41e0-b9f2-38797defa52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import toml\n",
    "import sleap_io as sio\n",
    "import re\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f078a5-5a3b-4166-b68c-21097824c42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ead32f-2b04-41b1-b453-a8a92c7dd1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/storage/home/hcoda1/4/jmarkowitz30/shared_folder/active_lab_members/markowitz_jeffrey/active_projects/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb15cc8-0d30-4ebe-bd82-fc1250c0e95e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_fname = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training/gridsearch_template/single_instance.json\")\n",
    "# template_fname = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training/gridsearch_template/bottomup_single_instance.json\")\n",
    "# template_fname = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training/gridsearch_template/topdown_centered_instance.json\")\n",
    "# MANUAL, all keypoints and kneejoints\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_final_model\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_subsample\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_subsample_morerepeats\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_parameter_sweep_part2\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_different_modalities_kneejoints\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_different_modalities_bottomup_v2\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_parameter_sweep_topdown\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_parameter_sweep_bottomup\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_parameter_sweep_bottomup_parttwo\")\n",
    "save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_subsample_reflectanceonly\")\n",
    "\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_final_model_kneejoints\")\n",
    "\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_subsample_fluo_aligned\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_manual_data_subsample_fluo_aligned_kneejoints\")\n",
    "\n",
    "\n",
    "# QDs, all keypoints\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera_large_sets\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_same_camera_v3\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera_v3\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras_v3\")\n",
    "\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras_large_models\")\n",
    "\n",
    "\n",
    "# QDs, kneejoints\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_same_camera_kneejoints_v3\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_heldout_camera_kneejoints_v3\")\n",
    "# save_dir = os.path.join(root_dir, \"keypoints_basler_nir_plexiglass_arena/sleap_training_round2/keypoints_from_qds_all_cameras_kneejoints_v3\")\n",
    "\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=False)\n",
    "# save_dir = os.path.dirname(template_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001c6880-63d0-4aa7-84c7-34cd7d1f2728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255dde79-744e-49c5-8f01-a98cb696e7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(template_fname, \"r\") as f:\n",
    "    template_dct = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8babbd-b426-4741-a0b8-ee7241739d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_keys = template_dct[\"optimization\"][\"augmentation_config\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c75c49-a1a6-4e0e-9882-952e1ea1e5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k, v in template_dct[\"model\"][\"backbone\"].items():\n",
    "    if v is not None:\n",
    "        use_backbone = k\n",
    "        break\n",
    "\n",
    "for k, v in template_dct[\"model\"][\"heads\"].items():\n",
    "    if v is not None:\n",
    "        use_head = k\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "510020e7-4975-4466-b3db-a4e15eec3ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dct = template_dct[\"model\"][\"backbone\"][use_backbone]\n",
    "head_dct = template_dct[\"model\"][\"heads\"][use_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6a8e706-3f44-4ecc-a852-ab9ea41d839b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (\"kneejoints\" in save_dir) and (\"from_qds\" in save_dir):\n",
    "    is_qd = True\n",
    "    # can fit this all in memory, don't need the embedded data\n",
    "    # training_data_lst = [\"../_labels_qd/training_data_qdots_round2_kneejoints_embed-False.slp\"]\n",
    "    training_data_lst = [\"../_labels_qd/kpoint_training_dataset_qd_alignment_kneejoints_reflect_only_round2_manual_labeling_nofluo_version-v1-embed-False.slp\"]\n",
    "elif (\"from_qds\" in save_dir):\n",
    "    is_qd = True\n",
    "    # training_data_lst = [\"../_labels_qd/training_data_qdots_round2_embed-True-sleap-version.slp\"]\n",
    "    # training_data_lst = [\"../_labels_qd/kpoint_training_dataset_qd_alignment_round2_manual_labeling_nofluo_v2-embed-False.slp\"]\n",
    "    # training_data_lst = [\"../_labels_qd/kpoint_training_dataset_qd_alignment_round2_manual_labeling_nofluo_version-v1-embed-False.slp\"]\n",
    "    training_data_lst = [\"../_labels_qd/kpoint_training_dataset_qd_alignment_round2_manual_labeling_nofluo_version-v1-embed-True-sleap-version.slp\"]\n",
    "elif (\"kneejoints\" in save_dir) and (\"modalities\" in save_dir) and (\"fluo_aligned\" in save_dir):\n",
    "    is_qd = False\n",
    "    nrepeats = 5\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-kneejoints*fluo-aligned.slp\"))\n",
    "elif (\"kneejoints\" in save_dir) and (\"modalities\" in save_dir) and (\"fluo_aligned\" not in save_dir):\n",
    "    is_qd = False\n",
    "    nrepeats = 5\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-kneejoints*None.slp\"))\n",
    "    training_data_lst = [_file for _file in training_data_lst if \"fluo-aligned\" not in _file]\n",
    "elif (\"modalities\" in save_dir) and (\"fluo_aligned\" in save_dir):\n",
    "    is_qd = False\n",
    "    nrepeats = 5\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-round2*fluo-aligned.slp\"))\n",
    "elif (\"modalities\" in save_dir) and (\"fluo_aligned\" not in save_dir):  \n",
    "    is_qd = False\n",
    "    nrepeats = 5\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-round2*None.slp\"))\n",
    "    training_data_lst = [_file for _file in training_data_lst if \"fluo-aligned\" not in _file]\n",
    "elif (\"fluo_aligned\" in save_dir):\n",
    "    is_qd = False\n",
    "    nrepeats = 2\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-round2_weights-None*fluo-aligned.slp\"))\n",
    "elif (\"kneejoints\" in save_dir):\n",
    "    is_qd = False\n",
    "    nrepeats = 2\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-kneejoints*None.slp\"))    \n",
    "    training_data_lst = [_file for _file in training_data_lst if (\"fluo-aligned\" not in _file) and (\"(1.0, 0.0)\" not in _file)]\n",
    "elif (\"subsample\" in save_dir) and (\"reflectanceonly\" in save_dir):\n",
    "    is_qd = False\n",
    "    nrepeats = 7\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-round2_weights-(0.0, 1.0)*None.slp\"))    \n",
    "    training_data_lst = [_file for _file in training_data_lst if \"fluo-aligned\" not in _file]\n",
    "elif (\"subsample\" in save_dir):\n",
    "    is_qd = False\n",
    "    nrepeats = 7\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-round2_weights-None*None.slp\"))    \n",
    "    training_data_lst = [_file for _file in training_data_lst if \"fluo-aligned\" not in _file]\n",
    "else:\n",
    "    is_qd = False\n",
    "    nrepeats = 2\n",
    "    training_data_lst = sorted(glob.glob(\"../_labels/basler-nir-plexiglass-arena-keypoints-fused-round2_weights-None*None.slp\"))    \n",
    "    training_data_lst = [_file for _file in training_data_lst if \"fluo-aligned\" not in _file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bb717ce-6fc8-43dc-91ba-b132952c2625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"same_camera\" in save_dir:\n",
    "    nrepeats = 1\n",
    "    camera_type = \"same\"\n",
    "elif \"heldout_camera\" in save_dir:\n",
    "    nrepeats = 1\n",
    "    camera_type = \"heldout\"\n",
    "elif is_qd:\n",
    "    nrepeats = 3\n",
    "    camera_type = \"all\"\n",
    "else:\n",
    "    camera_type = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cf64b23-dcd7-43c6-9623-9adbdb41ba2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preload_threshold = int(3e4)  # TYPICALLY 3e4, testing this out...\n",
    "fix_inds = True  # # fix indices of train/va/test datasets...\n",
    "fix_seed = True  # use same frames for each run/repeat\n",
    "if is_qd and (camera_type == \"heldout\"):\n",
    "    holdout_fraction = 0.05\n",
    "    test_fraction = 0.05\n",
    "elif is_qd and (camera_type == \"same\"):\n",
    "    holdout_fraction = 0.05\n",
    "    test_fraction = 0.05\n",
    "elif is_qd and (camera_type == \"all\") and (\"kneejoints\" in save_dir):\n",
    "    holdout_fraction = 0.05\n",
    "    test_fraction = 0.05\n",
    "elif is_qd and (camera_type == \"all\"):\n",
    "    holdout_fraction = 0.025\n",
    "    test_fraction = 0.025\n",
    "elif \"final_model\" in save_dir:\n",
    "    nrepeats = 5\n",
    "    holdout_fraction = 0.05\n",
    "    test_fraction = 0\n",
    "else:\n",
    "    holdout_fraction = 0.1\n",
    "    test_fraction = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "754f4c7b-e035-45ab-8e2c-52b9d35b3fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: ['../_labels/basler-nir-plexiglass-arena-keypoints-fused-round2_weights-(0.0, 1.0)_bpass-None.slp']\n",
      "N(repeats): 7\n",
      "Camera type: all\n",
      "Is QD data: False\n",
      "Validate fraction: 0.1\n",
      "Test fraction: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data: {training_data_lst}\")\n",
    "print(f\"N(repeats): {nrepeats}\")\n",
    "print(f\"Camera type: {camera_type}\")\n",
    "print(f\"Is QD data: {is_qd}\")\n",
    "print(f\"Validate fraction: {holdout_fraction}\")\n",
    "print(f\"Test fraction: {test_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58399858-0765-442f-bf76-415fcff60091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_dct[\"optimization\"][\"learning_rate_schedule\"][\"plateau_patience\"] = 5\n",
    "template_dct[\"optimization\"][\"early_stopping\"][\"plateau_patience\"] = 10\n",
    "template_dct[\"optimization\"][\"batch_size\"] = 4\n",
    "template_dct[\"optimization\"][\n",
    "    \"min_batches_per_epoch\"\n",
    "] = 200  # 800ish seems to be a hard limit in terms of performance...\n",
    "template_dct[\"optimization\"][\"epochs\"] = 100 if \"final_model\" not in save_dir else 200  # NORMALLY 100\n",
    "template_dct[\"data\"][\"labels\"][\"validation_fraction\"] = holdout_fraction\n",
    "template_dct[\"data\"][\"preprocessing\"][\"input_scaling\"] = 1.0\n",
    "\n",
    "# UNET\n",
    "if use_backbone == \"unet\":\n",
    "    # model_dct[\"filters\"] = 64\n",
    "    model_dct[\"filters\"] = 64\n",
    "    model_dct[\"max_stride\"] = 64\n",
    "    model_dct[\"stem_stride\"] = None\n",
    "    # model_dct[\"filters_rate\"] = 1.25\n",
    "    model_dct[\"filters_rate\"] = 1.5\n",
    "    model_dct[\"output_stride\"] = 4\n",
    "    model_dct[\"middle_block\"] = True\n",
    "    model_dct[\"up_interpolate\"] = True\n",
    "elif use_backbone == \"resnet\":\n",
    "    template_dct[\"data\"][\"preprocessing\"][\"target_height\"] = 1024\n",
    "    template_dct[\"data\"][\"preprocessing\"][\"target_width\"] = 1024\n",
    "    model_dct[\"upsampling\"][\"skip_connections\"] = \"concatenate\"\n",
    "    model_dct[\"upsampling\"][\"transposed_conv_kernel_size\"] = 8\n",
    "    model_dct[\"weights\"] = \"tunable\"\n",
    "    model_dct[\"upsampling\"][\"batch_norm\"] = True\n",
    "    model_dct[\"upsampling\"][\"filters\"] = 64\n",
    "    model_dct[\"version\"] = \"ResNet152\"\n",
    "else:\n",
    "    raise RuntimeError(\"Did not understand backbone\")\n",
    "\n",
    "if use_head == \"single_instance\":\n",
    "    head_dct[\"sigma\"] = 2.5\n",
    "    head_dct[\"output_stride\"] = 4\n",
    "\n",
    "template_dct[\"outputs\"][\"delete_viz_images\"] = True\n",
    "template_dct[\"outputs\"][\"runs_folder\"] = \"models\"\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"rotate\"] = True\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"translate\"] = True\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"scale\"] = True\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"gaussian_noise\"] = True\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"brightness\"] = False\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"contrast\"] = True\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"gaussian_noise_mean\"] = 5.0\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"gaussian_noise_stddev\"] = 1.0\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"translate_min\"] = -50\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"translate_max\"] = +50\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"scale_min\"] = 0.85\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"scale_max\"] = 1.15\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"rotation_min_angle\"] = -15\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"rotation_max_angle\"] = +15\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"brightness_min_val\"] = -20\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"brightness_max_val\"] = +20\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"contrast_min_gamma\"] = 0.5\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"contrast_max_gamma\"] = 2.0\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\n",
    "    \"random_flip\"\n",
    "] = True  # with symmetries saved good to go here...NORMALLY TRUE\n",
    "template_dct[\"optimization\"][\"augmentation_config\"][\"flip_horizontal\"] = True  # L/R flip (not up/down)...NORMALLY TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a07cf298-d136-4e6e-bf29-a837374ca6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_types = {\n",
    "    \"data_labels\": list(template_dct[\"data\"][\"labels\"].keys()) + [\"training_subsample\"],\n",
    "    \"backbone\": list(model_dct.keys()),\n",
    "    \"upsampling\": [],\n",
    "    \"head\": list(head_dct.keys()),\n",
    "    \"optimization\": list(template_dct[\"optimization\"].keys()),\n",
    "    \"augment\": list(template_dct[\"optimization\"][\"augmentation_config\"].keys()),\n",
    "    \"preprocessing\": list(template_dct[\"data\"][\"preprocessing\"].keys()),\n",
    "    \"hard_keypoint_mining\": list(template_dct[\"optimization\"][\"hard_keypoint_mining\"].keys()),\n",
    "    \"confmaps\": [],\n",
    "    \"pafs\": [],\n",
    "}\n",
    "if \"upsampling\" in model_dct.keys():\n",
    "    param_types[\"upsampling\"] = list(model_dct[\"upsampling\"].keys())\n",
    "if template_dct[\"model\"][\"heads\"][\"multi_instance\"] is not None:\n",
    "    param_types[\"confmaps\"] = list(template_dct[\"model\"][\"heads\"][\"multi_instance\"][\"confmaps\"].keys())\n",
    "    param_types[\"pafs\"] = list(template_dct[\"model\"][\"heads\"][\"multi_instance\"][\"pafs\"].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42098815-5729-4382-8dd5-c3016e95909f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_range = [  60, 125, 250, 500, 1000, 2500, 5000, 10000, 25000, 50000, 100000 ]\n",
    "if (\"labels_qd\" in training_data_lst[0]) and (camera_type == \"same\"):\n",
    "    training_subsample = [  60, 125, 250, 500, 1000, 2500, 5000, 10000, 15000, 20000, None] # same camera\n",
    "elif (\"labels_qd\" in training_data_lst[0]) and ((camera_type == \"heldout\") or (camera_type == \"all\")):\n",
    "    training_subsample = [  60, 125, 250, 500, 1000, 2500, 5000, 10000, 15000, 25000, 50000, 75000, None]\n",
    "else:\n",
    "    training_subsample = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bc42215-ea3e-415c-92b6-e7f1b87c7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED A CUSTOM SKELETON FOR BOTTOMUP\n",
    "force = True\n",
    "import shutil\n",
    "\n",
    "if \"bottomup\" in save_dir:\n",
    "\n",
    "    new_edges = [\n",
    "        (5, 4),  # back_middle → back_top\n",
    "        (5, 6),  # back_middle → back_bottom\n",
    "        (6, 2),  # back_bottom → hindleg_L\n",
    "        (6, 3),  # back_bottom → hindleg_R\n",
    "        (4, 0),  # back_top → foreleg_L\n",
    "        (4, 1),  # back_top → foreleg_R\n",
    "        (6, 7),  # back_bottom → tail_base\n",
    "        (7, 8),  # tail_base → tail_middle\n",
    "        (8, 9),  # tail_middle → tail_tip\n",
    "    ]\n",
    "    # preserve old nodes and symmetries, but need shallow tree structure for bottom up\n",
    "    # new custom skeleton filenames, if they don't exist write them and remap training_data_lst\n",
    "    new_training_data_lst = []\n",
    "    for _fname in tqdm(training_data_lst):\n",
    "        old_fname = os.path.splitext(_fname)[0]\n",
    "        new_fname = f\"{old_fname}_custom-skeleton.slp\"\n",
    "        if not os.path.exists(new_fname) or force:\n",
    "            old_labels = sio.load_file(_fname)\n",
    "            old_metadata_fname = _fname.replace(\".slp\", \".toml\")\n",
    "            old_skeleton = old_labels.skeleton\n",
    "\n",
    "            new_skeleton = sio.Skeleton(name=old_skeleton.name)\n",
    "            [new_skeleton.add_node(_node.name) for _node in old_skeleton.nodes]\n",
    "            [new_skeleton.add_edge(_edge) for _edge in new_edges]\n",
    "            [new_skeleton.add_symmetry(*_ind) for _ind in old_skeleton.symmetry_names]\n",
    "\n",
    "            new_labeled_frames = []\n",
    "            for lf in old_labels.labeled_frames:\n",
    "                use_points = lf.instances[0].points\n",
    "                use_points = {k.name: v for k, v in use_points.items()}\n",
    "                instance = sio.Instance(skeleton=new_skeleton, points=use_points)\n",
    "                labeled_frame = sio.LabeledFrame(video=lf.video, instances=[instance], frame_idx=lf.frame_idx)\n",
    "                new_labeled_frames.append(labeled_frame)\n",
    "\n",
    "            labels = sio.Labels(new_labeled_frames)\n",
    "            labels.save(new_fname)\n",
    "            new_metadata_fname = new_fname.replace(\".slp\", \".toml\")\n",
    "            shutil.copyfile(old_metadata_fname, new_metadata_fname)\n",
    "\n",
    "        new_training_data_lst.append(new_fname)\n",
    "        training_data_lst = new_training_data_lst\n",
    "\n",
    "else:\n",
    "    custom_skeleton = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2e19174-5568-4ae9-9b01-0961b5129333",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"topdown\" in save_dir:\n",
    "    template_dct[\"data\"][\"instance_cropping\"][\"crop_size\"] = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93eba9e6-008f-4c97-9b7b-5ea418c331ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gridsearch_dct = {\n",
    "    # DATA\n",
    "    \"training_labels\": training_data_lst,\n",
    "    # \"training_subsample\": [None],\n",
    "    \n",
    "    # RESNET\n",
    "    # \"version\": [\"ResNet152\"],\n",
    "    # \"weights\": [\"tunable\"],\n",
    "    # \"skip_connections\": [\"concatenate\"],\n",
    "    # \"block_stride\": [2, 4],\n",
    "    \"filters\": [64.],\n",
    "    \"filters_rate\": [2.],\n",
    "    # \"refine_convs\": [2],\n",
    "    # \"transposed_conv_kernel_size\": [8, 16],\n",
    "    \"max_stride\": [64],\n",
    "    # \"filters\": [64, 128, 256],\n",
    "    # \"filters_rate\": [2],\n",
    "    # \"output_stride\": [1],\n",
    "    # \"batch_size\": [1, 2, 4, 8],\n",
    "    # \"batch_norm\": [True],\n",
    "    \n",
    "    # UNET\n",
    "    # \"max_stride\": [16, 32, 64],\n",
    "    # \"filters\": [16, 32, 64],\n",
    "    # \"max_stride\": [32, 64, 96],\n",
    "    # \"filters\": [64],\n",
    "    # \"max_stride\": [64],\n",
    "    # \"filters\": [64, 96, 128],\n",
    "    # \"max_stride\": [64, 96],\n",
    "    # \"output_stride\": [1, 2, 4],\n",
    "    # \"up_interpolate\": [True],\n",
    "    # \"middle_block\": [True],\n",
    "    # \"output_stride\": [4, 8, 16, 32],\n",
    "    # \"output_stride\": [2, 4, 8],\n",
    "    # \"stem_stride\": [None],\n",
    "    # \"filters_rate\": [1.5],\n",
    "    # \"filters_rate\": [1.5, 2.],\n",
    "    # \"filters_rate\": [2],\n",
    "    # BOTTOMUP\n",
    "    # \"sigma_pafs\": [30, 40, 50, 60, 70, 80],\n",
    "    # \"output_stride_pafs\": [4],\n",
    "    # \"sigma_confmaps\": [2.5, 3.5],\n",
    "    \n",
    "    # OPTIMIZATION\n",
    "    # \"batch_size\": [4], # ADD BATCH SIZE 1!\n",
    "    # \"scale\": [.3],\n",
    "    # \"min_batches_per_epoch\": [800],\n",
    "    # \"filters\": [64, 96],\n",
    "    # \"online_mining\": [False, True],\n",
    "    # \"initial_learning_rate\": [1e-6, 2e-6, 3e-6],\n",
    "    # \"optimizer\": [\"adam\"],\n",
    "    # \"min_batches_per_epoch\": [200, 400],\n",
    "    \n",
    "    # PREPROCESSING\n",
    "    # \"ensure_rgb\": [True],\n",
    "    # \"imagenet_mode\": [None, \"tf\"],\n",
    "    # \"output_stride_backbone\": [4, 8, 12],\n",
    "    # \"input_scaling\": [1],\n",
    "    \n",
    "    # PRETRAINED\n",
    "    # \"pretrained\": [True],\n",
    "    # \"encoder\": [\"resnet101\", \"densenet121\"],\n",
    "    # \"decoder_batchnorm\": [False, True],\n",
    "    # \"filters\": [128, 256],\n",
    "    # \"filter_increase\": [128, 256],\n",
    "    # \"max_stride\": [32, 64],\n",
    "    \n",
    "    # HEAD\n",
    "    # \"sigma\": [1., 1.5, 2., 2.5, 3., 3.5, 4.], # param sweep\n",
    "    # \"output_stride_head\": [2., 4., 8.], # param sweep\n",
    "    \"sigma\": [2.5], # optimal\n",
    "    \"output_stride_head\": [4.], # optimal rounds 1/2\n",
    "    # \"sigma\": [0.5], # check part 2\n",
    "    \n",
    "    # AUGMENTATION\n",
    "    # \"translate\": [10, 50],\n",
    "    # \"scale\": [.05, .15, .3],\n",
    "    # \"rotate\": [5, 15],\n",
    "    # \"brightness\": [5, 20],\n",
    "    # \"gaussian_noise_mean\": [2.5, 5., 10.],\n",
    "    # \"gaussian_noise_stddev\": [2.5, 5., 10.],\n",
    "    # \"contrast_min_gamma\": [.5, .75],\n",
    "    # \"contrast_max_gamma\": [1.5, 2.],\n",
    "    # \"brightness\": [10., 20.],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "668dea4e-9d7d-45ef-a5db-a0b6c149ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"manual_data\" in save_dir and \"bottomup\" in save_dir:\n",
    "    gridsearch_dct[\"filters_rate\"] = [1.5] # typically 2\n",
    "elif \"manual_data\" in save_dir:\n",
    "    gridsearch_dct[\"filters_rate\"] = [2.] # typically 2\n",
    "\n",
    "if \"subsample\" in save_dir:\n",
    "    gridsearch_dct[\"training_subsample\"] = [50, 100, 200, 300, 400, 500, 600, None] # used this to address reviewer 3\n",
    "else:\n",
    "    gridsearch_dct[\"training_subsample\"] = training_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46788497-d034-4033-beff-291805bfe9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tomli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6036b59-4a5b-4704-8730-74a2881608bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_fname = os.path.splitext(training_data_lst[0])[0] + \".toml\"\n",
    "with open(metadata_fname, \"rb\") as f:\n",
    "    metadata = tomli.load(f)\n",
    "try:\n",
    "    metadata = metadata[\"segments_metadata\"]\n",
    "except KeyError:\n",
    "    metadata = metadata[\"frames\"]\n",
    "cameras = sorted(list(set([_[\"camera\"] for _ in metadata])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b3e522e-2e05-4af6-93b1-25e634d8ee8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if camera_type != \"all\":\n",
    "    gridsearch_dct[\"camera\"] = cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9294ac58-9888-46fb-af15-8adc86f4a619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid(gridsearch_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b044573-b16a-46c8-8a7d-0eaa6732c58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "re_camera = re.compile(r\"(Basler\\-[0-9|A-Z]+\\-[0-9|A-Z]+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "729f4ee6-3426-4c23-a29b-e746e8c92b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1748d761-96d5-470c-a67b-8a37b0c84506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = list(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9c577a6-04b7-4a29-91a1-f9f370060e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "26ccbe56-e600-4a25-bfbb-219078f9c7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cefe856684640128e1dab8474808f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(train): 50\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 50\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 50\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 50\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 50\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 50\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 50\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 100\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 100\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 100\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 100\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 100\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 100\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 100\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 200\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 200\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 200\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 200\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 200\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 200\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 200\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 300\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 300\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 300\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 300\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 300\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 300\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 300\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 400\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 400\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 400\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 400\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 400\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 400\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 400\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 500\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 500\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 500\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 500\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 500\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 500\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 500\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 600\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 600\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 600\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 600\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 600\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 600\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 600\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 689\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 689\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 689\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 689\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 689\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 689\n",
      "N(test): 86\n",
      "N(validate): 86\n",
      "N(train): 689\n",
      "N(test): 86\n",
      "N(validate): 86\n"
     ]
    }
   ],
   "source": [
    "for _params in tqdm(param_grid):\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    subsample_rng = np.random.default_rng(seed=100)\n",
    "    cur_camera = _params.pop(\"camera\", None)\n",
    "\n",
    "    try:\n",
    "        metadata_fname = os.path.splitext(_params[\"training_labels\"])[0] + \".toml\"\n",
    "        with open(metadata_fname, \"rb\") as f:\n",
    "            metadata = tomli.load(f)\n",
    "        try:\n",
    "            metadata = metadata[\"segments_metadata\"]\n",
    "        except KeyError:\n",
    "            metadata = metadata[\"frames\"]\n",
    "        sample_camera = [_[\"camera\"] for _ in metadata]\n",
    "    except FileNotFoundError:\n",
    "        sleap_obj = sio.load_file(_params[\"training_labels\"])\n",
    "        sample_camera = [re_camera.search(_.video.filename).group(1) for _ in sleap_obj.labeled_frames]\n",
    "\n",
    "    for _repeat in range(nrepeats):\n",
    "        _iter_params = copy.deepcopy(_params)\n",
    "        new_params = copy.deepcopy(template_dct)\n",
    "\n",
    "        model_dct = new_params[\"model\"][\"backbone\"][use_backbone]\n",
    "\n",
    "        # new_params[\"data\"][\"preprocessing\"][\"input_scaling\"] = _params[\"input_scaling\"]\n",
    "        for k, v in _iter_params.items():\n",
    "            if (k in param_types[\"backbone\"]) or k.endswith(\"backbone\"):\n",
    "                model_dct[k.replace(\"_backbone\", \"\")] = v\n",
    "            elif (k in param_types[\"data_labels\"]) or k.endswith(\"data_labels\"):\n",
    "                new_params[\"data\"][\"labels\"][k.replace(\"_data_labels\", \"\")] = v\n",
    "            elif (k in param_types[\"upsampling\"]) or k.endswith(\"upsampling\"):\n",
    "                model_dct[\"upsampling\"][k.replace(\"_upsampling\", \"\")] = v\n",
    "            elif (k in param_types[\"optimization\"]) or k.endswith(\"optimization\"):\n",
    "                new_params[\"optimization\"][k.replace(\"_optimization\", \"\")] = v\n",
    "            elif (k in param_types[\"hard_keypoint_mining\"]) or k.endswith(\"hard_keypoint_mining\"):\n",
    "                new_params[\"optimization\"][\"hard_keypoint_mining\"][k.replace(\"_hard_keypoint_mining\", \"\")] = v\n",
    "            elif (k in param_types[\"preprocessing\"]) or k.endswith(\"preprocessing\"):\n",
    "                new_params[\"data\"][\"preprocessing\"][k.replace(\"_preprocessing\", \"\")] = v\n",
    "            elif (k in param_types[\"head\"]) or k.endswith(\"head\"):\n",
    "                new_params[\"model\"][\"heads\"][\"single_instance\"][k.replace(\"_head\", \"\")] = v\n",
    "            elif (k in param_types[\"confmaps\"]) or k.endswith(\"confmaps\"):\n",
    "                new_params[\"model\"][\"heads\"][\"multi_instance\"][\"confmaps\"][k.replace(\"_confmaps\", \"\")] = v\n",
    "            elif (k in param_types[\"pafs\"]) or k.endswith(\"pafs\"):\n",
    "                new_params[\"model\"][\"heads\"][\"multi_instance\"][\"pafs\"][k.replace(\"_pafs\", \"\")] = v\n",
    "            elif (k in param_types[\"augment\"]) or k.endswith(\"augment\"):\n",
    "                use_k = k.replace(\"_augment\", \"\")\n",
    "                try:\n",
    "                    match_min = [_ for _ in augment_keys if f\"{use_k}_min\" in _][0]\n",
    "                    match_max = [_ for _ in augment_keys if f\"{use_k}_max\" in _][0]\n",
    "                    if use_k == \"scale\":\n",
    "                        origin = 1\n",
    "                    else:\n",
    "                        origin = 0\n",
    "                    new_params[\"optimization\"][\"augmentation_config\"][match_min] = origin - v\n",
    "                    new_params[\"optimization\"][\"augmentation_config\"][match_max] = origin + v\n",
    "                except IndexError:\n",
    "                    new_params[\"optimization\"][\"augmentation_config\"][use_k] = v\n",
    "            else:\n",
    "                raise RuntimeError(f\"Did not understand {k}\")\n",
    "\n",
    "        # make interlaced lists...\n",
    "        # labels = sio.load_slp(new_params[\"data\"][\"labels\"][\"training_labels\"])\n",
    "        training_subsample = new_params[\"data\"][\"labels\"].pop(\"training_subsample\", None)\n",
    "        # nlabels = len(labels)\n",
    "\n",
    "        if fix_inds:\n",
    "            if fix_seed:\n",
    "                rng = np.random.default_rng(seed=0)\n",
    "    \n",
    "            # HERE same/heldout/etc.\n",
    "            if camera_type == \"all\":\n",
    "                cameras = sorted(list(set(sample_camera)))\n",
    "            elif camera_type == \"heldout\":\n",
    "                cameras = sorted(list(set(sample_camera)))\n",
    "            elif camera_type == \"same\":\n",
    "                cameras = sorted(list(set(sample_camera)))\n",
    "                cameras = [_cam for _cam in cameras if _cam == cur_camera]\n",
    "\n",
    "            model_dct = new_params[\"model\"][\"backbone\"][use_backbone]\n",
    "            samples_by_camera = {}\n",
    "            for _camera in cameras:\n",
    "                samples_by_camera[_camera] = rng.permutation(\n",
    "                    [i for i, camera in enumerate(sample_camera) if camera == _camera]\n",
    "                ).tolist()\n",
    "\n",
    "            if (camera_type == \"all\") or (camera_type == \"same\"):\n",
    "                # can use same frame pool here...\n",
    "                nlabels = sum([len(_) for _ in samples_by_camera.values()])\n",
    "\n",
    "                # val_fraction = new_params[\"data\"][\"labels\"][\"validation_fraction\"]\n",
    "                train_fraction = 1 - holdout_fraction - test_fraction\n",
    "                ntrain = np.floor(nlabels * train_fraction).astype(\"int\")\n",
    "                nholdout = np.floor(nlabels * holdout_fraction).astype(\"int\")\n",
    "                ntest = np.floor(nlabels * test_fraction).astype(\"int\")\n",
    "\n",
    "                all_idx = []\n",
    "                stop = False\n",
    "                # use same/heldout/etc here\n",
    "                while not stop:\n",
    "                    for _camera in cameras:\n",
    "                        try:\n",
    "                            all_idx.append(samples_by_camera[_camera].pop())\n",
    "                        except IndexError:\n",
    "                            continue\n",
    "                    stop = all(\n",
    "                        [len(v) == 0 for v in samples_by_camera.values()]\n",
    "                    )  # stop once we've exhausted all frames...\n",
    "                train_idx = all_idx[:ntrain]\n",
    "                if (training_subsample is not None) and (training_subsample < len(train_idx)):\n",
    "                    train_idx = subsample_rng.choice(train_idx, size=training_subsample).tolist()\n",
    "                elif training_subsample is not None:\n",
    "                    warnings.warn(\n",
    "                        f\"Training subsample exceeds availability: {cur_camera} nlabels {nlabels} subsample {training_subsample}\"\n",
    "                    )\n",
    "                    continue\n",
    "                validate_idx = all_idx[ntrain:ntrain + nholdout]\n",
    "                test_idx = all_idx[ntrain + nholdout:ntrain + nholdout + ntest]\n",
    "            else:\n",
    "                # HELDOUT, train on OTHER cameras, test on THIS camera\n",
    "                train_cameras = [_cam for _cam in cameras if _cam != cur_camera]\n",
    "                ntrain_labels = sum([len(v) for k, v in samples_by_camera.items() if k in train_cameras])\n",
    "                ntest_labels = len(samples_by_camera[cur_camera])\n",
    "                ntotal_labels = ntrain_labels + ntest_labels\n",
    "\n",
    "                all_train_idx = []\n",
    "                stop = False\n",
    "                # use same/heldout/etc here\n",
    "                while not stop:\n",
    "                    for _camera in train_cameras:\n",
    "                        try:\n",
    "                            all_train_idx.append(samples_by_camera[_camera].pop())\n",
    "                        except IndexError:\n",
    "                            continue\n",
    "                    stop = all(\n",
    "                        [len(v) == 0 for k, v in samples_by_camera.items() if k in train_cameras]\n",
    "                    )  # stop once we've exhausted all frames...\n",
    "\n",
    "                all_heldout_idx = samples_by_camera[cur_camera]\n",
    "                nholdout = np.floor(ntest_labels * holdout_fraction).astype(\"int\")\n",
    "                ntest = np.floor(ntest_labels * test_fraction).astype(\"int\")\n",
    "\n",
    "                train_idx = all_train_idx\n",
    "                if (training_subsample is not None) and (training_subsample < len(train_idx)):\n",
    "                    train_idx = subsample_rng.choice(train_idx, size=training_subsample).tolist()\n",
    "                elif training_subsample is not None:\n",
    "                    warnings.warn(\n",
    "                        f\"Training subsample exceeds availability: {cur_camera} nlabels {ntrain_labels} subsample {training_subsample}\"\n",
    "                    )\n",
    "                    continue\n",
    "                validate_idx = all_heldout_idx[:nholdout]\n",
    "                test_idx = all_heldout_idx[nholdout:nholdout + ntest]\n",
    "\n",
    "            new_params[\"data\"][\"labels\"][\"training_inds\"] = train_idx\n",
    "            new_params[\"data\"][\"labels\"][\"validation_inds\"] = validate_idx\n",
    "            if len(test_idx) > 0:\n",
    "                new_params[\"data\"][\"labels\"][\"test_inds\"] = test_idx\n",
    "            else:\n",
    "                new_params[\"data\"][\"labels\"][\"test_inds\"] = None\n",
    "            new_params[\"data\"][\"labels\"][\"split_by_inds\"] = True\n",
    "\n",
    "        # nframes = len(sleap.load_file(new_params[\"data\"][\"labels\"][\"training_labels\"]).labeled_frames)\n",
    "\n",
    "        new_params[\"optimization\"][\"preload_data\"] = (len(train_idx) < preload_threshold) and (\n",
    "            len(validate_idx) < preload_threshold\n",
    "        )\n",
    "\n",
    "        new_name = \"unet_\"\n",
    "        for k, v in _params.items():\n",
    "            if k == \"training_labels\":\n",
    "                use_v = os.path.basename(v)\n",
    "                new_name += f\"{k}-{use_v}_\"\n",
    "            else:\n",
    "                new_name += f\"{k}-{v}_\"\n",
    "        # new_name = new_name[:-1]\n",
    "        new_name += f\"repeat-{_repeat}\"\n",
    "        if cur_camera is not None:\n",
    "            new_name += f\"-{cur_camera}\"\n",
    "        print(f\"N(train): {len(train_idx)}\")\n",
    "        print(f\"N(test): {len(test_idx)}\")\n",
    "        print(f\"N(validate): {len(validate_idx)}\")\n",
    "\n",
    "        new_params[\"outputs\"][\"run_name\"] = new_name\n",
    "        with open(os.path.join(save_dir, f\"{new_name}.json\"), \"w\") as f:\n",
    "            json.dump(new_params, f, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b627f81-c04c-49a7-b2dd-c33b7c5f23c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone': {'leap': None,\n",
       "  'unet': {'stem_stride': None,\n",
       "   'max_stride': 64,\n",
       "   'output_stride': 4,\n",
       "   'filters': 64.0,\n",
       "   'filters_rate': 2.0,\n",
       "   'middle_block': True,\n",
       "   'up_interpolate': True,\n",
       "   'stacks': 1},\n",
       "  'hourglass': None,\n",
       "  'resnet': None,\n",
       "  'pretrained_encoder': None},\n",
       " 'heads': {'single_instance': {'part_names': None,\n",
       "   'sigma': 2.5,\n",
       "   'output_stride': 4.0,\n",
       "   'loss_weight': 1.0,\n",
       "   'offset_refinement': False},\n",
       "  'centroid': None,\n",
       "  'centered_instance': None,\n",
       "  'multi_instance': None,\n",
       "  'multi_class_bottomup': None,\n",
       "  'multi_class_topdown': None},\n",
       " 'base_checkpoint': None}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b91b5fd-d262-489a-9b32-ef39789ec7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gridsearch_metadata = {\n",
    "    \"gridsearch_spec\": gridsearch_dct,\n",
    "    \"nrepeats\": nrepeats,\n",
    "    \"camera_type\": camera_type,\n",
    "    \"is_qd\": is_qd,\n",
    "    \"validate_fraction\": holdout_fraction,\n",
    "    \"test_fraction\": test_fraction,\n",
    "    \"template_fname\": template_fname\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0257e27-10c6-46cb-8ba5-890b1696548f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"gridsearch_parameters.toml\"), \"w\") as f:\n",
    "    toml.dump(gridsearch_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed4188-9e07-405e-ad73-e5e5af19479e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis (local)",
   "language": "python",
   "name": "data_analysis_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
