{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17da30-45c1-48dc-88ed-cb3c5371e855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c775946-4a9b-4a64-a6ff-90f6381e867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toml\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "from markovids import vid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74fb1d3-952f-459f-b833-c83c13f7d7a7",
   "metadata": {},
   "source": [
    "## User functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9612ca0-fb33-4124-b97b-8a1b8940f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_filter(x, sigma):\n",
    "    return cv2.GaussianBlur(x, [0, 0], sigma, sigma)\n",
    "\n",
    "def bp_filter(x, sigma1, sigma2, clip=True):\n",
    "    if (sigma1 == 0) or (sigma1 is None):\n",
    "        return x\n",
    "    elif (sigma2 == 0) or (sigma2 is None):\n",
    "        return lp_filter(x, sigma1)\n",
    "    else:\n",
    "        return np.clip(\n",
    "            lp_filter(x, sigma1) - lp_filter(x, sigma2),\n",
    "            0 if clip == True else -np.inf,\n",
    "            np.inf,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af107698-b97a-483a-a089-cbd4147b49cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52498777/apply-matplotlib-or-custom-colormap-to-opencv-image\n",
    "def mpl_to_cv2_colormap(cmap_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "\n",
    "    # step from min to max, strip alpha, rgb to bgr\n",
    "    color_range = sm.to_rgba(np.linspace(0, 1, 256), bytes=True)[:, 2::-1]\n",
    "    return color_range.reshape(256, 1, 3)\n",
    "\n",
    "\n",
    "def minmax_scale(batch_frames):\n",
    "    use_min = batch_frames.min(axis=(1, 2), keepdims=True)\n",
    "    use_max = batch_frames.max(axis=(1, 2), keepdims=True)\n",
    "\n",
    "    # normalize between 0-1\n",
    "    batch_frames = (batch_frames - use_min) / (use_max - use_min)\n",
    "    batch_frames[batch_frames < 0] = 0\n",
    "    batch_frames[batch_frames > 1] = 1\n",
    "    return batch_frames\n",
    "\n",
    "\n",
    "def intensity_to_rgba(frame, minval=1800, maxval=2200, colormap=cv2.COLORMAP_TURBO):\n",
    "    disp_frame = frame.copy().astype(\"float\")\n",
    "    disp_frame -= minval\n",
    "    disp_frame[disp_frame < 0] = 0\n",
    "    disp_frame /= np.abs(maxval - minval)\n",
    "    disp_frame[disp_frame >= 1] = 1\n",
    "    disp_frame *= 255\n",
    "    bgr_frame = cv2.applyColorMap(disp_frame.astype(np.uint8), colormap)\n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # new_frame[:, :, :3] = rgb_frame / 255.0\n",
    "    return rgb_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65fe40-ace5-4ab8-aec6-c52542eaa2a7",
   "metadata": {},
   "source": [
    "# Load in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4ac18-f85f-44bd-9f17-bb62c916e755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"/storage/home/hcoda1/4/jmarkowitz30/shared_folder/active_lab_members/markowitz_jeffrey/active_projects/quantum_dots/timecourse_02/\"\n",
    "background_path = \"_bground\"\n",
    "frame_path = \"_proc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc145107-d115-4099-a50e-f91df604bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data_file = os.path.join(os.path.dirname(base_dir), \"../timecourse_02_calibration_v2.toml\")\n",
    "calibration_data = toml.load(calibration_data_file)\n",
    "cameras = sorted(list(calibration_data[\"intrinsics\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0daf7d2-f6b4-4309-b153-d3520da9592f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minval = 0\n",
    "maxval = 255\n",
    "use_cmap = plt.matplotlib.cm.turbo\n",
    "use_cmap = mpl_to_cv2_colormap(use_cmap)\n",
    "\n",
    "step_size = 250  # save every Nth frame from each video, (15 for joints, 500 for standard fused)\n",
    "pad = 0  # pad with a 20px border\n",
    "dry_run = False\n",
    "bpass = (3, 20)\n",
    "weights = (0.85, 0.15)\n",
    "\n",
    "eps = 2\n",
    "randomize_priority = True  # randomize label order\n",
    "use_camera_order = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee06e1d-e412-46f1-90cf-8cb8b9ac890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_info(dir, cameras={}):\n",
    "    include_cameras = []\n",
    "    for _cam in cameras:\n",
    "        reflect_path = os.path.join(dir, frame_path, f\"{cameras[0]}-reflectance.avi\")\n",
    "        if os.path.exists(reflect_path):\n",
    "            include_cameras.append(_cam)\n",
    "\n",
    "    reader = vid.io.AutoReader(reflect_path)\n",
    "    nframes = reader.nframes\n",
    "    return {\"cameras\": include_cameras, \"nframes\": nframes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a5cff-0876-4efb-9e16-ecbf1983573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir, cameras={}, spacing=250, **kwargs):\n",
    "    data = {}\n",
    "    for _cam in cameras:\n",
    "        data[_cam] = {}\n",
    "        reflect_path = os.path.join(dir, frame_path, f\"{_cam}-reflectance.avi\")\n",
    "        fluo_path = os.path.join(dir, frame_path, f\"{_cam}-fluorescence.avi\")\n",
    "        reader = vid.io.AutoReader(reflect_path)\n",
    "        nframes = reader.nframes\n",
    "        frame_range = range(0, nframes, spacing)\n",
    "\n",
    "        frames = reader.get_frames(frame_range)\n",
    "        reader.close()\n",
    "\n",
    "        reader = vid.io.AutoReader(fluo_path, **kwargs)\n",
    "        fluo_frames = reader.get_frames(frame_range)\n",
    "        reader.close()\n",
    "\n",
    "        data[_cam][\"reflect\"] = frames\n",
    "        data[_cam][\"filepath_reflect\"] = reflect_path\n",
    "\n",
    "        use_bground_path = os.path.join(dir, frame_path, background_path, f\"{_cam}-fluorescence.hdf5\")\n",
    "        with h5py.File(use_bground_path, \"r\") as f:\n",
    "            rolling_bgrounds = f[\"bground\"][()]\n",
    "            idxs = f[\"frame_idxs\"][()]\n",
    "\n",
    "        for i, (_idx, _frame) in enumerate(zip(frame_range, fluo_frames)):\n",
    "            use_bground = np.argmin(np.abs(idxs - _idx))\n",
    "            fluo_frames[i] = np.clip(_frame - rolling_bgrounds[use_bground], 0, 255).astype(\"uint8\")\n",
    "\n",
    "        data[_cam][\"fluo\"] = fluo_frames\n",
    "        data[_cam][\"filepath_fluo\"] = fluo_path\n",
    "\n",
    "    return data, frame_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78db1e4-ef12-4a6b-a8a6-75de3f610419",
   "metadata": {},
   "source": [
    "# Gather all data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d68496-1aee-4965-a7b9-23cec1f5b06f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "dat_paths = sorted(glob.glob(os.path.join(base_dir, \"session*\")))\n",
    "dat_paths = [_ for _ in dat_paths if os.path.isdir(_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d968c-d016-4d30-a4e0-12991fba5ba0",
   "metadata": {},
   "source": [
    "# Filter by metadata (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a789d86-c519-4505-893f-5964742c2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include subjects\n",
    "exclude_subjects = [\"qd_knee_01\", \"qd_knee_02\"]\n",
    "# include days\n",
    "exclude_dates = pd.to_datetime([\"2024-08-08\", \"2024-08-09\"])\n",
    "exclude_paths = []\n",
    "# max_date = None\n",
    "max_date = \"2024-06-13\"  # for fused keypoint data, from our beads injections\n",
    "\n",
    "for _path in dat_paths:\n",
    "    metadata = toml.load(os.path.join(_path, \"metadata.toml\"))\n",
    "    subject = metadata[\"user_input\"][\"subject\"].lower()\n",
    "    # print(subject)\n",
    "    start_time = pd.to_datetime(metadata[\"start_time\"]).floor(\"d\")\n",
    "    date_match = start_time in exclude_dates\n",
    "    passed_expiration = False\n",
    "    if max_date is not None:\n",
    "        passed_expiration = start_time > pd.to_datetime(max_date)\n",
    "    subject_match = subject in exclude_subjects\n",
    "    if date_match or subject_match or passed_expiration:\n",
    "        exclude_paths.append(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128aa112-b304-45d5-b1db-3ad305358c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_paths = sorted(list(set(dat_paths) - set(exclude_paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d23d3d-500f-493a-9328-ecfd28410969",
   "metadata": {},
   "source": [
    "# Test on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7632b0-2f64-4254-a1b2-06d83dc8710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5913020-924f-4ffb-ac65-e2bad1f92f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, frame_range = load_data(dat_paths[0], spacing=spacing, threads=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12adbad7-8ed6-4a2f-b920-bc59e6ccd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_frame = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e4246-01ef-477a-a72f-66054bf5d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for _camera in tqdm(cameras):\n",
    "    for i, _frame in tqdm(enumerate(test_data[_camera][\"fluo\"])):\n",
    "        proc_fluo = bp_filter(_frame.astype(\"float32\"), *bpass)\n",
    "        proc_fluo[proc_fluo <= 0] = 0\n",
    "        cnt += proc_fluo.max() >= fluo_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bca04-51fb-4e9e-899b-c1189b15b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_im = weights[0] * proc_fluo + weights[1] * test_data[_camera][\"reflect\"][i]\n",
    "new_im = (new_im - new_im.min()) / (new_im.max() - new_im.min())\n",
    "new_im *= 255\n",
    "new_im = new_im.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3cc2ee-dafe-4ce1-8b94-862df8c52bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_im, cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db7909-1a47-4b61-a01c-4221d914053a",
   "metadata": {},
   "source": [
    "# Get what already exists on segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd3174-1824-40a3-a9b2-da8a028213cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from segments import SegmentsClient\n",
    "import json\n",
    "\n",
    "# You can find your api key at https://segments.ai/account\n",
    "api_key = os.getenv(\"SEGMENTSAPI\")\n",
    "client = SegmentsClient(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98515c-3e7f-47e8-8665-db604386ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"jmarkow/basler-nir-plexiglass-arena-keypoints-fused-round2\"\n",
    "# dataset_name = \"jmarkow/basler-nir-plexiglass-arena-keypoints-fused-kneejoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c26d1-bfa5-4fa1-845a-bf74c44e6ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_name = \"jmarkow/lucid-helios2plus-openfield-mouse-cables\"\n",
    "samples = client.get_samples(dataset_name)\n",
    "filenames_uploaded = []\n",
    "for _sample in samples:\n",
    "    filenames_uploaded.append(os.path.basename(_sample.metadata[\"img_path\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b74da4-8620-4686-95f5-dd0869a51d10",
   "metadata": {},
   "source": [
    "# Export data to directory first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f1fb8-f62b-4bad-a334-743796e65933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d39c6-b02f-4b36-96e5-c98317dfc4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames_to_upload = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822feb9b-3322-4b6f-9267-a7f74d24f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo_threshold = 50\n",
    "dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec35a4-95c2-44d3-b4a4-9ca92b02e797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_dir = \"/storage/home/hcoda1/4/jmarkowitz30/shared_folder/active_lab_members/markowitz_jeffrey/active_projects/keypoints_basler_nir_plexiglass_arena/segments_ai_labeling_export_fused_round2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f9654-dce8-4bcf-8439-df289549b304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export_dir = \"/home/jmarkow/data_dir/active_projects/keypoints_basler_nir_plexiglass_arena/segments_ai_labeling_export_fused_kneejoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e797cf0-ac2a-4dbe-81c5-14a12c520616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(export_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c5289-c293-4d72-9f45-77ccf0b223a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_info = get_data_info(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088355e-6eb6-4beb-aa86-309e9a1fef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cameras = dat_info[\"cameras\"]\n",
    "frame_range = range(0, dat_info[\"nframes\"], step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d86bcc-4e75-4006-9534-fa62712f0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_template = \"{}_{}_{}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc1d4a-bfdc-44c3-b231-647affcf6baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _path in tqdm(dat_paths):\n",
    "\n",
    "    dat_info = get_data_info(_path, cameras=cameras)\n",
    "    use_cameras = dat_info[\"cameras\"]\n",
    "    frame_range = range(0, dat_info[\"nframes\"], step_size)\n",
    "\n",
    "    fileparts = os.path.normpath(_path).split(os.path.sep)\n",
    "    session_name = fileparts[-1].split(\" \")[0]\n",
    "\n",
    "    missing_files = []\n",
    "    for _cam in use_cameras:\n",
    "        for _idx in frame_range:\n",
    "            missing_files.append(filename_template.format(session_name, _cam, _idx))\n",
    "    # missing_files = [filename_template.format(session_name, fname, _idx) for _idx in read_frames]\n",
    "    missing_files = [_file for _file in missing_files if not os.path.exists(os.path.join(export_dir, _file))]\n",
    "\n",
    "    if len(missing_files) < 1:\n",
    "        continue\n",
    "    try:\n",
    "        dat, frame_range = load_data(_path, cameras=cameras, spacing=step_size, threads=10)\n",
    "    except FileNotFoundError:\n",
    "        warnings.warn(f\"Error loading {_path}\")\n",
    "        continue\n",
    "\n",
    "    for _cam in use_cameras:\n",
    "        for _frame, _idx in enumerate(frame_range):\n",
    "\n",
    "            # alright...\n",
    "            proc_fluo = bp_filter(dat[_cam][\"fluo\"][_frame].astype(\"float32\"), *bpass)\n",
    "            proc_fluo[proc_fluo <= 0] = 0\n",
    "\n",
    "            # INSERT FLUORESCENCE THRESHOLD HERE!\n",
    "            if proc_fluo.max() < fluo_threshold:\n",
    "                continue\n",
    "\n",
    "            new_im = weights[0] * proc_fluo + weights[1] * dat[_cam][\"reflect\"][_frame]\n",
    "            new_im = (new_im - new_im.min()) / (new_im.max() - new_im.min())\n",
    "            new_im *= 255\n",
    "            new_im = new_im.astype(\"uint8\")\n",
    "\n",
    "            # skip if filename is already in the directory...\n",
    "            # NOTE that this should be unique, session_name is session (and host)\n",
    "            # filename already includes camera\n",
    "            # idx is frame number\n",
    "            filename_export = os.path.join(export_dir, filename_template.format(session_name, _cam, _idx))\n",
    "            filename_base = os.path.basename(filename_export)\n",
    "\n",
    "            use_frame = np.pad(new_im, ((pad, pad), (pad, pad)), mode=\"constant\", constant_values=0)\n",
    "            export_frame = intensity_to_rgba(use_frame, minval=minval, maxval=maxval, colormap=use_cmap)[:, :, :3]\n",
    "\n",
    "            targetImage = Image.fromarray(export_frame)\n",
    "            metadata = PngInfo()\n",
    "            metadata.add_text(\"pad\", str(pad))\n",
    "            metadata.add_text(\"frame_index\", str(_idx))\n",
    "            metadata.add_text(\"camera\", _cam)\n",
    "            metadata.add_text(\"dat_path_fluo\", dat[_cam][\"filepath_fluo\"])\n",
    "            metadata.add_text(\"dat_path_reflect\", dat[_cam][\"filepath_reflect\"])\n",
    "            metadata.add_text(\"img_path\", filename_export)\n",
    "\n",
    "            if not dry_run:\n",
    "                if not os.path.exists(filename_export):\n",
    "                    targetImage.save(filename_export, pnginfo=metadata)\n",
    "                else:\n",
    "                    warnings.warn(f\"{filename_export} already exists, skipping...\")\n",
    "            else:\n",
    "                if not os.path.exists(filename_export):\n",
    "                    warnings.warn(f\"Would have saved {filename_export}...\")\n",
    "                else:\n",
    "                    warnings.warn(f\"{filename_export} already exists, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27737f3e-74d0-45b6-8b58-3757ab249e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_exported = sorted(glob.glob(os.path.join(export_dir, \"*.png\")))\n",
    "filenames_to_upload = [_fname for _fname in filenames_exported if os.path.basename(_fname) not in filenames_uploaded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475976e1-c7f9-406b-90ac-c4e418d13cbf",
   "metadata": {},
   "source": [
    "# Upload new data to segments.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feaf152-748e-4d17-ba1d-6cd55754b188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(filenames_to_upload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805c492-b848-4186-9836-efa6211ceaf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe85787-305f-457d-b114-d938412ff907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _filename in tqdm(filenames_to_upload):\n",
    "    with open(_filename, \"rb\") as f:\n",
    "        use_filename = os.path.basename(_filename)\n",
    "        asset = client.upload_asset(f, use_filename)\n",
    "    image_url = asset.url\n",
    "    urls.append(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7651b16-0b5e-4c2b-9448-20e5e3e92a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _name, _url in tqdm(zip(filenames_to_upload, urls), total=len(filenames_to_upload)):\n",
    "    # convert numeric metadata prior to adding to dataset...\n",
    "    metadata = Image.open(_name).text\n",
    "    metadata[\"pad\"] = int(metadata[\"pad\"])\n",
    "    metadata[\"frame_index\"] = int(metadata[\"frame_index\"])\n",
    "    attributes = {\"image\": {\"url\": _url}}\n",
    "    sample = client.add_sample(dataset_name, os.path.basename(_name), attributes, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78a840-aa3c-4ae6-90ff-e68fa5fec2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16450b69-6b7b-4f98-b31e-887c4f25f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = client.get_samples(dataset_name, per_page=10000, label_status=[\"UNLABELED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237be79a-3264-493f-a30a-de71394a1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_by_camera = {}\n",
    "for _cam in cameras:\n",
    "    samples_by_camera[_cam] = [_sample for _sample in samples if _sample.metadata[\"camera\"] == _cam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4dc3c-a880-45ee-b9e9-c5209c58e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_by_camera = {}\n",
    "rng = np.random.default_rng(seed=0)\n",
    "for _cam in cameras:\n",
    "    idx = np.arange(len(samples_by_camera[_cam]))\n",
    "    idx = rng.permutation(idx)\n",
    "    indices_by_camera[_cam] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c68e6f-103e-42ad-9d61-b9541c5560ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority = len(samples)\n",
    "frame_idx = range(len(samples_by_camera[_cam]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a26db85-147a-4e59-bc64-74c53876a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _idx in tqdm(frame_idx):\n",
    "    for _cam in cameras:\n",
    "        try:\n",
    "            use_sample = samples_by_camera[_cam][_idx]\n",
    "            client.update_sample(use_sample.uuid, priority=priority)\n",
    "            priority -= 1\n",
    "        except IndexError:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis (local)",
   "language": "python",
   "name": "data_analysis_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
