{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf449c-18e7-4dcc-a194-9de011757c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52844345-aa05-4c4d-bf9b-b7ff7e10e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import copy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage\n",
    "import toml\n",
    "import glob\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "from markovids import vid\n",
    "from scipy import spatial, signal, ndimage\n",
    "import sleap_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9b2f24-2f03-473f-bb43-96ff3f96c0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f965787c-4239-486c-864e-0b8fac252614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33f37ab-f1ed-4616-87d6-7309d817880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. add hampel filtering...\n",
    "# 2. add kalman filtering..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6e564-6e34-41c6-b628-197e2387ee78",
   "metadata": {},
   "source": [
    "## Gather data and predicted keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c11b5d1c-4ba4-458d-9a78-265b15b84d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hindleg_only = False\n",
    "base_dir = \"/home/jmarkow/data_dir/active_projects/quantum_dots/timecourse_02\"\n",
    "# base_dir = \"/home/jmarkow/data_dir/active_projects/quantum_dots/timecourse_02_joints\"\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d221c580-b0eb-4a8a-8fdb-256d9defcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"joint\" in base_dir:\n",
    "    kpoint_dir = \"/home/jmarkow/data_dir/active_projects/keypoints_basler_nir_plexiglass_arena/keypoint_inference_kneejoints_export_fused_weights-None_bpass-None\"\n",
    "else:\n",
    "    kpoint_dir = \"/home/jmarkow/data_dir/active_projects/keypoints_basler_nir_plexiglass_arena/keypoint_inference_export_fused_weights-None_bpass-None\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47e8f65-dbeb-4c9e-801e-bfa0bca6cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleap_files = sorted(glob.glob(os.path.join(kpoint_dir, \"**\", \"*.slp\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1397baa-c4e3-4c54-9f55-56c30207cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "bground_path = \"_bground\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee1c44-d397-4635-9369-025fe94a81ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a847c3-c1b2-4b6e-96f0-444bfb3a3f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8843feebe5a4b749708ad74e9810920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sleap_dcts = []\n",
    "for _sfile in tqdm(sleap_files):\n",
    "    metadata_fname = _sfile.replace(\".predictions.slp\",\".toml\")\n",
    "    metadata = toml.load(metadata_fname)\n",
    "    # sleap_dcts[_sfile] = {}\n",
    "    _file_dct = {}\n",
    "    _file_dct[\"sleap_fname\"] = _sfile\n",
    "    # _file_dect = sleap_dcts[_sfile]\n",
    "    # _file_dct[\"kpoint_predictions_fname\"] = _sfile\n",
    "    _file_dct[\"fluo_fname\"] = metadata[\"export_metadata\"][\"file\"].replace(\"-reflectance.avi\",\"-fluorescence.avi\")\n",
    "    \n",
    "    fluo_basename = os.path.splitext(os.path.basename(_file_dct[\"fluo_fname\"]))[0]\n",
    "    fluo_dirname = os.path.dirname(_file_dct[\"fluo_fname\"]) \n",
    "    bground_fname = os.path.join(fluo_dirname, bground_path, f\"{fluo_basename}.hdf5\")\n",
    "\n",
    "    _file_dct[\"fluo_bground_fname\"] = bground_fname\n",
    "    _file_dct[\"reflect_fname\"] = metadata[\"export_metadata\"][\"file\"]\n",
    "    _file_dct[\"kpoint_avi_fname\"] = _sfile.replace(\".predictions.slp\",\"\")\n",
    "    _file_dct[\"start_time\"] = metadata[\"export_metadata\"][\"original_metadata\"][\"start_time\"]\n",
    "    _file_dct[\"camera\"] = metadata[\"export_metadata\"][\"cam\"]\n",
    "    # _file_dct[\"kpoint_arr\"] = sleap_io.load_slp(_file_dct[\"sleap_fname\"]).numpy(return_confidence=True).squeeze()\n",
    "\n",
    "    sleap_dcts.append(_file_dct)\n",
    "\n",
    "    # get kpoints, then center of mass in masked image around kpoint, do some basic\n",
    "    # confidence thresholding and filtering..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1dc92c-9729-40c9-b402-1a9eef63d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66171969/compute-center-of-mass-in-numpy\n",
    "def center_of_mass(array: np.ndarray, yidx = None, xidx = None):\n",
    "    total = array.sum()\n",
    "    # alternatively with np.arange as well\n",
    "    if yidx is None:\n",
    "        yidx = range(array.shape[0])\n",
    "\n",
    "    if xidx is None:\n",
    "        xidx = range(array.shape[1])\n",
    "\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        y_coord = (array.sum(axis=1) @ yidx) / total\n",
    "        x_coord = (array.sum(axis=0) @ xidx) / total\n",
    "    return x_coord, y_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a18ba9d5-24a6-4888-8bc2-abe8769f5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpoint_qd_df(\n",
    "    sleap_fname=None,\n",
    "    fluo_fname=None,\n",
    "    fluo_bground_fname=None,\n",
    "    batch_size=500,\n",
    "    search_radius=5,\n",
    "    confidence_threshold=0, # used no confidence threshold for first run, then .5 for joints\n",
    "    reader_kwargs={\"threads\": 2},\n",
    "    force=True,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    save_file = os.path.splitext(sleap_fname)[0] + \".parquet\"\n",
    "    if (not force) and os.path.exists(save_file):\n",
    "        return pd.read_parquet(save_file)\n",
    "\n",
    "    dset = sleap_io.load_slp(sleap_fname)\n",
    "    \n",
    "    # TODO: also read in frame index...\n",
    "    kpoint_arr = dset.numpy(return_confidence=True).squeeze()\n",
    "    skeleton = dset.skeleton\n",
    "\n",
    "    search_obj = skimage.morphology.disk(radius=search_radius).astype(\"float\")\n",
    "    search_y, search_x = np.where(search_obj>0)\n",
    "    center = search_obj.shape[0] // 2\n",
    "    xx = np.arange(search_obj.shape[1] + 1)\n",
    "    yy = np.arange(search_obj.shape[0] + 1)\n",
    "    xx -= center\n",
    "    yy -= center\n",
    "\n",
    "    with h5py.File(fluo_bground_fname, \"r\") as f:\n",
    "        bgrounds = f[\"bground\"][()]\n",
    "        bgrounds_idxs = f[\"frame_idxs\"][()]\n",
    "\n",
    "    reader = vid.io.AutoReader(fluo_fname, **reader_kwargs)\n",
    "    nframes = reader.nframes\n",
    "    width, height = reader.frame_size\n",
    "\n",
    "    dcts = []\n",
    "    batches = range(0, nframes, batch_size)\n",
    "    for _batch in tqdm(batches):\n",
    "        frame_idx = range(_batch, _batch + batch_size)\n",
    "        use_frames = reader.get_frames(frame_idx)\n",
    "        frame_idx = list(frame_idx)\n",
    "\n",
    "        for idx, _frame in tqdm(zip(frame_idx, use_frames), total=len(frame_idx)):\n",
    "            kpoints = kpoint_arr[idx]\n",
    "            \n",
    "            for kpoint_idx, _kpoint in enumerate(kpoints):\n",
    "                if ~np.isnan(_kpoint[0]) and (_kpoint[2] >= confidence_threshold):\n",
    "\n",
    "                    use_bground_idx = np.argmin(np.abs(bgrounds_idxs - idx))\n",
    "                    bground_sub = np.clip(\n",
    "                        _frame.astype(\"int16\") - bgrounds[use_bground_idx], 0, np.inf\n",
    "                    )\n",
    "\n",
    "                    kpoint_x_idx = int(np.round(_kpoint[0]))\n",
    "                    kpoint_y_idx = int(np.round(_kpoint[1]))\n",
    "\n",
    "                    new_coords = xx + kpoint_x_idx, yy + kpoint_y_idx\n",
    "                    xrange = (new_coords[0][0], new_coords[0][-1])\n",
    "                    yrange = (new_coords[1][0], new_coords[1][-1]) \n",
    "                    try:\n",
    "                        masked_bground_sub = search_obj * bground_sub[slice(*yrange), slice(*xrange)].astype(\"float\")\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    \n",
    "                    com = center_of_mass(masked_bground_sub, yidx=range(*yrange), xidx=range(*xrange))\n",
    "                    fluo_ave = np.nanmean(masked_bground_sub[search_y,search_x])\n",
    "                    fluo_peak = np.nanmax(masked_bground_sub[search_y,search_x])\n",
    "                    \n",
    "                    _dct = {\n",
    "                        \"com_x\": com[0],\n",
    "                        \"com_y\": com[1],\n",
    "                        \"kpoint_name\": skeleton.nodes[kpoint_idx].name,\n",
    "                        \"kpoint_x\": _kpoint[0],\n",
    "                        \"kpoint_y\": _kpoint[1],\n",
    "                        \"kpoint_confidence\": _kpoint[2],\n",
    "                        \"kpoint_to_com_l2\": np.hypot(\n",
    "                            _kpoint[0] - com[0], _kpoint[1] - com[1]\n",
    "                        ),\n",
    "                        \"fluo_ave\": fluo_ave,\n",
    "                        \"fluo_peak\": fluo_peak,\n",
    "                        \"frame_index\": idx,\n",
    "                    }\n",
    "\n",
    "                    dcts.append(_dct)\n",
    "\n",
    "    reader.close()\n",
    "    store_dat = pd.DataFrame(dcts)\n",
    "    store_dat[\"sleap_file\"] = sleap_fname\n",
    "    store_dat[\"fluo_file\"] = fluo_fname\n",
    "    store_dat[\"search_radius\"] = search_radius\n",
    "    for k, v in kwargs.items():\n",
    "        store_dat[k] = v\n",
    "    store_dat.to_parquet(save_file)\n",
    "    return store_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc5d45e5-bfac-4e55-bcfc-53a4b248a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = []\n",
    "for _dct in sleap_dcts:\n",
    "    _delay = delayed(get_kpoint_qd_df)(\n",
    "        sleap_fname=_dct[\"sleap_fname\"],\n",
    "        fluo_fname=_dct[\"fluo_fname\"],\n",
    "        fluo_bground_fname=_dct[\"fluo_bground_fname\"],\n",
    "        start_time=_dct[\"start_time\"],\n",
    "        kpoint_avi_fname=_dct[\"kpoint_avi_fname\"],\n",
    "        camera=_dct[\"camera\"],\n",
    "        search_radius=7.5,\n",
    "        force=False,\n",
    "        # confidence_threshold=0 if \"joint\" in base_dir else 0,\n",
    "    )\n",
    "    delays.append(_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf39a64-78cf-4a0c-b8af-98b437b4aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably save intermediate files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d37a3a-1f0e-4013-94f8-dbae885e8623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend MultiprocessingBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Batch computation too fast (0.18516826629638672s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=7)]: Done  11 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=7)]: Done  22 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=7)]: Done  45 out of  52 | elapsed:    1.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=7)]: Done  52 out of  52 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "dat = Parallel(n_jobs=7, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10bab6e7-338d-47cb-b87b-a306623cccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_df = pd.concat(dat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fba8f83-4a5f-48d0-9cae-c0f4cadd4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_df[\"reflect_file\"] = qd_df[\"fluo_file\"].str.replace(\"-fluorescence.avi\",\"-reflectance.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14500ae7-3dee-4908-8be9-0f372fec5052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jmarkow/data_dir/active_projects/quantum_dots/_analysis'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = toml.load(\"config.toml\")\n",
    "config[\"dirs\"][\"analysis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110d149b-7734-40d2-861f-60aab7e2e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"joint\" in base_dir:\n",
    "    qd_df.to_parquet(os.path.join(config[\"dirs\"][\"analysis\"], \"kpoint_kneejoints_qd_alignment.parquet\"))\n",
    "else:\n",
    "    qd_df.to_parquet(os.path.join(config[\"dirs\"][\"analysis\"], \"kpoint_qd_alignment.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce3d7351-0f20-484f-9dfa-459ded010c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold_hi = .6 if (\"joint\" in base_dir or hindleg_only) else .3\n",
    "fluo_ave_threshold_hi = 25\n",
    "l2_threshold_hi = np.inf\n",
    "min_confidence_per_frame = .7\n",
    "min_nkpoints = 1 if (\"joint\" in base_dir or hindleg_only) else 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec0bc36d-fd6c-4d60-a54d-bdb5506fbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition2 = f\"(kpoint_confidence > {confidence_threshold_hi}\"\n",
    "condition2 += f\" and fluo_ave > {fluo_ave_threshold_hi}\"\n",
    "condition2 += f\" and kpoint_to_com_l2 < {l2_threshold_hi})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba407b93-982c-4010-a47e-952f55845082",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_qd_df = qd_df.query(\n",
    "    f\"{condition2}\"\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54f0c1ee-0131-4954-8853-64bedb484d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hindleg_only:\n",
    "    # only use one mouse here since we're comparing to joints, which only has one mouse\n",
    "    filtered_qd_df = filtered_qd_df.loc[filtered_qd_df[\"sleap_file\"].str.lower().str.contains(\"qd_beads_07\")].copy()\n",
    "    filtered_qd_df = filtered_qd_df.query(\"kpoint_name.str.contains('hindleg')\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4387615-76de-49f4-9bb4-86fe8fa1ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_qd_df = filtered_qd_df.groupby([\"kpoint_avi_fname\", \"frame_index\"]).filter(\n",
    "    lambda x: x[\"kpoint_confidence\"].min() >= min_confidence_per_frame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cebb334-ea38-4aa9-852a-047db29ecdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_qd_df = filtered_qd_df.groupby([\"kpoint_avi_fname\", \"frame_index\"]).filter(\n",
    "    lambda x: len(x) >= min_nkpoints \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2b34495-d6dd-4a35-a4ae-cbf58b211096",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"joint\" in base_dir:\n",
    "    filtered_qd_df = filtered_qd_df.loc[~filtered_qd_df[\"sleap_file\"].str.contains(\"\\+48h\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42f9a5d2-c1fb-4c69-85af-2b3cb8e87002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe require n kpoints per frame..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0811c1c-5952-421b-942f-b68a0793f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aedb3ee-8808-46e4-891c-46f6a4fbf935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(x):\n",
    "    if len(x) > 1:\n",
    "        return spatial.distance.pdist(x.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2212dce-2904-4bb5-ad57-911b970fff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_qd_df.groupby([\"sleap_file\", \"frame_index\"])[[\"kpoint_x\", \"kpoint_y\"]].apply(\n",
    "#     get_distance\n",
    "# ).dropna().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf213978-57ce-4060-ae4e-fb0e7fc1b0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174548"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_qd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d3784-fedc-4838-9b06-4dd70369d24f",
   "metadata": {},
   "source": [
    "# Make new training file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c044d-5484-4c13-874c-67549a8eb8e7",
   "metadata": {},
   "source": [
    "1. ADD HAMPEL FILTER?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cedce67-ea1d-479a-87de-4f508d572a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 16:00:29.335355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jmarkow/miniconda3/envs/sleap-analysis/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-08-15 16:00:29.335389: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sleap_io as sio\n",
    "import sleap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d8317dc-6c37-4d72-8605-6668193d0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"joint\" in base_dir:\n",
    "    old_labels_fname = \"/home/jmarkow/data_dir/active_projects/keypoints_basler_nir_plexiglass_arena/sleap_training/_labels/train_frames_kneejoints_fused_weights-None_bpass-None.slp\"\n",
    "else:\n",
    "    old_labels_fname = \"/home/jmarkow/data_dir/active_projects/keypoints_basler_nir_plexiglass_arena/sleap_training/_labels/train_frames_fused_weights-None_bpass-None.slp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4deb5ded-ac89-43f5-9a22-5981d4ac853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_skeleton = sleap.load_file(old_labels_fname).skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "067c12a1-5ae3-4a94-9737-3a8b5606b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hindleg_only:\n",
    "    new_skeleton = sleap.skeleton.Skeleton(name=use_skeleton.name)\n",
    "    new_skeleton.add_node(\"hindleg_L\")\n",
    "    new_skeleton.add_node(\"hindleg_R\")\n",
    "    new_skeleton.add_symmetry(\"hindleg_L\",\"hindleg_R\")\n",
    "    use_skeleton = new_skeleton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0e8b4a9-eaab-4ff8-baac-28d4cd4f716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_labels = sio.load_slp(old_labels_fname)\n",
    "# use_skeleton = old_labels.skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a854ff18-6981-483d-95a3-0ba4ba6712e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to idx \n",
    "kpoint_idx_mapping = {key: i for i, key in enumerate(sorted(filtered_qd_df[\"kpoint_name\"].unique()))}\n",
    "idx_kpoint_mapping = {v: k for k, v in kpoint_idx_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "484b7bd3-717c-4965-bd6a-a08b3545889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = len(kpoint_idx_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "379031c0-c6a1-4b23-a71e-f52cce10533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_qd_df[\"kpoint_idx\"] = filtered_qd_df[\"kpoint_name\"].map(kpoint_idx_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3b05f65-79b8-4e7c-ac47-27e7f66ca4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY KPOINT X/Y HERE\n",
    "def convert_to_point_array(df, x_key = \"com_x\", y_key= \"com_y\", n_nodes=n_nodes):\n",
    "    # sort by kpoint num\n",
    "    assert(len(df) == df[\"kpoint_name\"].nunique())\n",
    "    new_array = np.full((n_nodes, 2), fill_value=np.nan)\n",
    "    for _idx, _row in df.iterrows():\n",
    "        new_array[int(_row[\"kpoint_idx\"]), 0] = _row[x_key]\n",
    "        new_array[int(_row[\"kpoint_idx\"]), 1] = _row[y_key]\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "428a5caf-02c7-4014-916b-165f76f300ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by fluo_name, reflect_name, or kpoint_avi_fname to use various things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "506074c9-af0c-468f-a3e7-a66eb809d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_vid_key = \"reflect_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8e37a37-30e2-4b24-8ee0-82dbfed7be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = filtered_qd_df.groupby([use_vid_key, \"frame_index\"]).apply(\n",
    "    convert_to_point_array, include_groups=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b0f0e43-970f-4bb4-916d-5b9e597a6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_videos = sorted(set([_key[0] for _key, _arr in arrays.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10b92d73-597d-4aa9-a2e2-726b19f18147",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = {}\n",
    "for _vid in uniq_videos:\n",
    "    videos[_vid] = sleap.io.video.Video.from_filename(_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b42606d1-a100-4d51-a27d-c79eab511139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48c795d5d604049bd819877be729fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_labeled_frames = []\n",
    "for (_vid, _frame_idx), _arr in tqdm(arrays.items(), total=len(arrays)):\n",
    "    use_points = {}\n",
    "    for i, _point in enumerate(_arr):\n",
    "        x, y = _point\n",
    "        name = idx_kpoint_mapping[i]\n",
    "        use_points[name] = sleap.instance.Point(x=x, y=y, visible=True, complete=True)\n",
    "    if len(use_points) > 0:\n",
    "        instance = sleap.instance.Instance(skeleton=use_skeleton, points=use_points)\n",
    "        labeled_frame = sleap.instance.LabeledFrame(\n",
    "            video=videos[_vid], instances=[instance], frame_idx=_frame_idx\n",
    "        )\n",
    "        all_labeled_frames.append(labeled_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "175806ae-4df0-45c6-adfc-fd8b92288fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlabeled_frames = len(all_labeled_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e62692b-9fd7-4b0a-ab15-bb1a958b5a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:segments.client:Initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from segments import SegmentsClient\n",
    "\n",
    "# You can find your api key at https://segments.ai/account\n",
    "api_key = \"XXX\"\n",
    "client = SegmentsClient(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "381e301d-3421-478b-a2e3-4db1d9ad418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"joint\" in base_dir:\n",
    "    dataset_name = \"jmarkow/basler-nir-plexiglass-arena-keypoints-fused-kneejoints\"\n",
    "else:\n",
    "    dataset_name = \"jmarkow/basler-nir-plexiglass-arena-keypoints-fused\"\n",
    "samples = client.get_samples(dataset_name, per_page=10000, label_status=[\"LABELED\",\"REVIEWED\"])\n",
    "pre_segments_labels = [(client.get_label(_sample.uuid), _sample) for _sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16cb4c98-367b-45df-ba26-bcc045878715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "959b8872-44f1-4ed9-a87d-642703ecec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we don't have any file/frame collisions. If so remove from the new training data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9da450f-a092-461f-8f1b-01541aac9007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d30806614a4662964ce0a55eea897e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_idxs = []\n",
    "for i, _labeled_frame in tqdm(enumerate(all_labeled_frames), total=len(all_labeled_frames)):\n",
    "    chk_file = _labeled_frame.video.filename\n",
    "    chk_string = f\"{os.sep}\".join(chk_file.split(os.sep)[-3:]) # last three ropes in session name\n",
    "    chk_frame_idx = int(_labeled_frame.frame_idx)\n",
    "    keep = True\n",
    "    for (_label, _sample) in pre_segments_labels:\n",
    "        match_string = f\"{os.sep}\".join(_sample.metadata[\"dat_path_reflect\"].split(os.sep)[-3:]) # last three ropes in session name\n",
    "        match_frame_idx = int(_sample.metadata[\"frame_index\"])\n",
    "        frame_distance = np.abs(match_frame_idx - chk_frame_idx)\n",
    "        # if files match we need to be N frames away to keep\n",
    "        if (match_string == chk_string) and (frame_distance < 10):\n",
    "            keep = False\n",
    "            break\n",
    "    # if a match was never found let's keep it!\n",
    "    if keep:\n",
    "        keep_idxs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66d68ba7-1d96-42bd-b41f-bdc264728867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137655\n"
     ]
    }
   ],
   "source": [
    "print(len(keep_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74734c58-9986-4053-9745-33cc60aacf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labeled_frames_nomatch = [all_labeled_frames[i] for i in keep_idxs]\n",
    "nlabeled_frames = len(all_labeled_frames_nomatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c8b0cb3-21b6-4f00-b440-fc04400e0c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137655"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlabeled_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8acc819-55cc-415f-9a71-8631dfe52b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_range = [  60, 125, 250, 500, 1000, 2500, 5000, 10000, 25000, 50000, 100000 ]\n",
    "label_range = [  60, 125, 250, 500, 1000, 2500, 5000, 10000, 20000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d921d5a-6bd1-4672-8a35-15602554bfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2231cf-6333-45c0-8644-c1b9cc60d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02faaf00c825450286be7849a308511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = \"/home/jmarkow/data_dir/active_projects/keypoints_basler_nir_plexiglass_arena/sleap_training/_labels_qd/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for _nlabels in tqdm(label_range):\n",
    "    if \"joint\" in base_dir:\n",
    "        save_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"training_data_qdots_kneejoints_nframes-{_nlabels}_vidtype-{use_vid_key}_minkpoints-{min_nkpoints}.slp\",\n",
    "        )\n",
    "    elif hindleg_only:\n",
    "        save_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"training_data_qdots_hindleg_nframes-{_nlabels}_vidtype-{use_vid_key}_minkpoints-{min_nkpoints}.slp\",\n",
    "        )\n",
    "    else:    \n",
    "        save_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"training_data_qdots_v2_nframes-{_nlabels}_vidtype-{use_vid_key}_minkpoints-{min_nkpoints}.slp\",\n",
    "        )\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "\n",
    "    choose_frames = np.round(np.linspace(1, nlabeled_frames - 1, _nlabels)).astype(\n",
    "        \"int\"\n",
    "    )\n",
    "    save_labeled_frames = [all_labeled_frames_nomatch[i] for i in choose_frames]\n",
    "\n",
    "    labels = sleap.Labels(labeled_frames=save_labeled_frames)\n",
    "    labels.save(save_path, with_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f85b79f1-9f8e-4a81-b83f-67d995250178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7d0a9b479946b89608fab1f968d746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_dir = \"/home/jmarkow/data_dir/active_projects/keypoints_basler_nir_plexiglass_arena/sleap_training/_labels_qd_noimages/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for _nlabels in tqdm(label_range):\n",
    "    if \"joint\" in base_dir:\n",
    "        save_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"training_data_qdots_kneejoints_nframes-{_nlabels}_vidtype-{use_vid_key}_minkpoints-{min_nkpoints}.slp\",\n",
    "        )\n",
    "    elif hindleg_only:\n",
    "        save_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"training_data_qdots_hindleg_nframes-{_nlabels}_vidtype-{use_vid_key}_minkpoints-{min_nkpoints}.slp\",\n",
    "        )\n",
    "    else:    \n",
    "        save_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"training_data_qdots_v2_nframes-{_nlabels}_vidtype-{use_vid_key}_minkpoints-{min_nkpoints}.slp\",\n",
    "        )\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "\n",
    "    choose_frames = np.round(np.linspace(1, nlabeled_frames - 1, _nlabels)).astype(\n",
    "        \"int\"\n",
    "    )\n",
    "    save_labeled_frames = [all_labeled_frames_nomatch[i] for i in choose_frames]\n",
    "\n",
    "    labels = sleap.Labels(labeled_frames=save_labeled_frames)\n",
    "    labels.save(save_path, with_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4785c27e-4f90-4d58-862e-f0c3525ea6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdc293-758a-4fcc-beb9-f08b0b385eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sleap-analysis]",
   "language": "python",
   "name": "conda-env-sleap-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
