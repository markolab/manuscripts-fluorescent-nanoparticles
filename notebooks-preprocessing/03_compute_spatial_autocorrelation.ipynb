{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdf449c-18e7-4dcc-a194-9de011757c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25fd5e0-464c-4c6e-93d1-1082c5d1aa1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage\n",
    "import toml\n",
    "import glob\n",
    "import joblib\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "from markovids import pcl, vid, depth\n",
    "from qd_analysis.util import clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3b9332-f833-44cb-9c90-289d79778622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433b263a-08c3-4d7d-8dee-748fdae52e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9b2f24-2f03-473f-bb43-96ff3f96c0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bdc7c55-8b45-4a9a-b34c-0933260b578a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmentation_dir = \"_segmentation_tau-0-pretrain\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6af78-dd92-4b5f-a533-a31359064f6a",
   "metadata": {},
   "source": [
    "## User functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592119f7-f923-45ce-8ade-21979df3b079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_spatial_autocorr(\n",
    "    dat_file,\n",
    "    spacing=400,\n",
    "    bground_spacing=2000,\n",
    "    bground_agg_func=np.mean,\n",
    "    reader_kwargs={\"threads\": 2},\n",
    "    distortion_coeffs=None,\n",
    "    intrinsic_matrix=None,\n",
    "    segmentation_dir=segmentation_dir,\n",
    "    bground_dir=\"_bground\",\n",
    "    output_dir=\"_autocorr\",\n",
    "    force=False,\n",
    "):\n",
    "    # TODO compute summary stats inside and outside of ROI\n",
    "\n",
    "    metadata = toml.load(os.path.join(os.path.dirname(dat_file), \"../metadata.toml\"))\n",
    "    dirname, fname_reflectance = os.path.split(\n",
    "        dat_file.replace(\"fluorescence\", \"reflectance\")\n",
    "    )\n",
    "    fname_reflectance, ext = os.path.splitext(fname_reflectance)\n",
    "    fname_fluorescence, ext = os.path.splitext(os.path.basename(dat_file))\n",
    "\n",
    "    segmentation_path = os.path.join(\n",
    "        dirname, segmentation_dir, f\"{fname_reflectance}.hdf5\"\n",
    "    )\n",
    "    bground_path = os.path.join(dirname, bground_dir, f\"{fname_fluorescence}.hdf5\")\n",
    "    save_file = os.path.join(dirname, output_dir, f\"{fname_fluorescence}.parquet\")\n",
    "\n",
    "    os.makedirs(os.path.join(dirname, output_dir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dirname, bground_dir), exist_ok=True)\n",
    "\n",
    "    save_file = os.path.join(dirname, output_dir, \"autocorr_data.pkl\")\n",
    "\n",
    "    if os.path.exists(save_file) and not force:\n",
    "        try:\n",
    "            results = joblib.load(save_file)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    reader = vid.io.AutoReader(\n",
    "        dat_file,\n",
    "        **reader_kwargs,\n",
    "    )\n",
    "    frame_range = range(0, reader.nframes, spacing)\n",
    "\n",
    "    if os.path.exists(segmentation_path):\n",
    "        with h5py.File(segmentation_path) as f:\n",
    "            masks = f[\"labels\"][frame_range]\n",
    "            masks = masks.astype(\"uint8\")\n",
    "    else:\n",
    "        warnings.warn(f\"No mask found {dat_file}\")\n",
    "        reader.close()\n",
    "        return None\n",
    "\n",
    "    if os.path.exists(bground_path):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            with h5py.File(bground_path, \"r\") as f:\n",
    "                rolling_bgrounds = f[\"bground\"][()]\n",
    "                idxs = f[\"frame_idxs\"][()]\n",
    "            frames = reader.get_frames(frame_range)\n",
    "            # frames = reader.undistort_frames(frames)\n",
    "    else:\n",
    "        warnings.warn(f\"No bground found {dat_file}\")\n",
    "        reader.close()\n",
    "        return None\n",
    "\n",
    "    bground_sub = np.zeros(frames.shape, dtype=\"int16\")\n",
    "    for i, (_idx, _frame) in enumerate(zip(frame_range, frames)):\n",
    "        use_bground = np.argmin(np.abs(idxs - _idx))\n",
    "        bground_sub[i] = np.clip(_frame - rolling_bgrounds[use_bground], 0, 255)\n",
    "        bground_sub[i][masks[i] <= 0] = 0  # mask out non-mouse stuff...\n",
    "\n",
    "    if intrinsic_matrix is not None:\n",
    "        for i in range(len(masks)):\n",
    "            masks[i] = cv2.undistort(\n",
    "                masks[i], intrinsic_matrix, distortion_coeffs\n",
    "            )\n",
    "        for i in range(len(bground_sub)):\n",
    "            bground_sub[i] = cv2.undistort(\n",
    "                bground_sub[i], intrinsic_matrix, distortion_coeffs\n",
    "            )\n",
    "    \n",
    "    # bground_sub = np.clip(frames - bground[None, ...], 0, 255).astype(\"int16\")\n",
    "    corrs = []\n",
    "    for i in range(len(bground_sub)):\n",
    "        corr_frame = bground_sub[i].astype(\"float\")\n",
    "        _corr = signal.correlate(corr_frame, corr_frame)\n",
    "        # check normalization...\n",
    "        _corr_norm = _corr / (np.sqrt(np.sum(corr_frame**2) ** 2))\n",
    "        corrs.append(_corr_norm)\n",
    "\n",
    "    nframes, height, width = bground_sub.shape\n",
    "    ave_corr = np.mean(corrs, axis=0)\n",
    "\n",
    "    results = {\n",
    "        \"ave_corr\": ave_corr,\n",
    "        # \"metadata\": metadata,\n",
    "        \"intrinsic_matrix\": intrinsic_matrix,\n",
    "        \"distortion_coeffs\": distortion_coeffs,\n",
    "        \"start_time\": metadata[\"start_time\"],\n",
    "        \"filename\": dat_file\n",
    "    }\n",
    "    for k, v in metadata[\"user_input\"].items():\n",
    "        results[k] = v\n",
    "    joblib.dump(results, save_file)\n",
    "    return results\n",
    "    # return bground_sub, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e2ce6-b8f0-4d26-a151-cd0f1dd38f84",
   "metadata": {},
   "source": [
    "# Quantify fluorescence length-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ffd27b-4c9e-4c91-bd46-6cdc798e33bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"/mnt/data/jmarkow/active_projects/quantum_dots/timecourse_01\"\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = \"/mnt/data/jmarkow/active_projects/quantum_dots/timecourse_01_agarose_beads\"\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc5bf6d3-7b99-409f-a274-5137b5a922fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = toml.load(\"/home/jmarkow/data_dir/active_projects/quantum_dots/timecourse_01_calibration.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b945e7-e8fd-42de-9e02-61b10692f509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80ec74758a14602855bb9a21fb847b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get subject names and filter that stuff...\n",
    "metadata = {}\n",
    "for _file in tqdm(fluo_files):\n",
    "    metadata[_file] = toml.load(os.path.join(os.path.dirname(_file), \"../metadata.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5fc09a-9fe2-4cdf-9ae8-d511dd8568c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 780 out of 780 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "delays = []\n",
    "for _file in fluo_files:\n",
    "    cam = os.path.basename(_file).replace(\"-fluorescence.avi\", \"\")\n",
    "    delays.append(\n",
    "        delayed(get_spatial_autocorr)(\n",
    "            _file,\n",
    "            intrinsic_matrix=np.array(calibration_data[\"intrinsics\"][cam]),\n",
    "            distortion_coeffs=np.array(calibration_data[\"distortion_coeffs\"][cam]),\n",
    "        )\n",
    "    )\n",
    "print(len(delays))\n",
    "dat = Parallel(n_jobs=-1, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d26d27-cb04-4f1f-8363-aa9fccc17ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"/mnt/data/jmarkow/active_projects/quantum_dots/timecourse_02\"\n",
    "fluo_files = sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = \"/mnt/data/jmarkow/active_projects/quantum_dots/timecourse_02_joints\"\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))\n",
    "base_dir = \"/mnt/data/jmarkow/active_projects/quantum_dots/timecourse_03\"\n",
    "fluo_files += sorted(glob.glob(os.path.join(base_dir, \"**\", \"Basler*fluorescence.avi\"), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4840794-90ba-4565-99c1-76d16105290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = [toml.load(\"/home/jmarkow/data_dir/active_projects/quantum_dots/timecourse_02_calibration_v1.toml\"),\n",
    "                    toml.load(\"/home/jmarkow/data_dir/active_projects/quantum_dots/timecourse_02_calibration_v2.toml\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85cfe23e-4bf5-4457-88a2-05713281e49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0df854ea3374e72b8696c1a926c02d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get subject names and filter that stuff...\n",
    "metadata = {}\n",
    "for _file in tqdm(fluo_files):\n",
    "    metadata[_file] = toml.load(os.path.join(os.path.dirname(_file), \"../metadata.toml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a258c-adbc-474c-b802-06e8b3dff792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   55.8s\n"
     ]
    }
   ],
   "source": [
    "delays = []\n",
    "for _file in fluo_files:\n",
    "    cam = os.path.basename(_file).replace(\"-fluorescence.avi\", \"\")\n",
    "    timestamp = pd.to_datetime(metadata[_file][\"start_time\"])\n",
    "    if timestamp.floor(\"d\") <= pd.to_datetime(\"2024-06-10\"):\n",
    "        use_calibration_data = calibration_data[0]\n",
    "    else:\n",
    "        use_calibration_data = calibration_data[1]\n",
    "    # for 0610 load v1 after that load v2 calibration data...\n",
    "    delays.append(\n",
    "        delayed(get_spatial_autocorr)(\n",
    "            _file,\n",
    "            intrinsic_matrix=np.array(use_calibration_data[\"intrinsics\"][cam]),\n",
    "            distortion_coeffs=np.array(use_calibration_data[\"distortion_coeffs\"][cam]),\n",
    "        )\n",
    "    )\n",
    "print(len(delays))\n",
    "dat2 = Parallel(n_jobs=-1, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f74410-f312-4540-91cd-61464b63bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat += dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba048b5c-3450-4a72-a57e-ea0b5eedee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include +1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4f7ef-df45-4625-a048-aaff576090ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lag = 50 # in px\n",
    "z = 300  # in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423863e-2dac-4b9f-bbff-c1f5d5b14fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = dat[0][\"ave_corr\"].shape\n",
    "im_height, im_width = height //2, width // 2\n",
    "height_lags = np.arange(-height // 2, height // 2) + 1\n",
    "width_lags = np.arange(-width // 2, width // 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875d348-445f-474a-84f2-a6cbf8bb03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_height = np.abs(height_lags) <= max_lag\n",
    "use_width = np.abs(width_lags) <= max_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d225f-2e58-4ef7-9a30-a3eeea841cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dat = [_dat for _dat in dat if _dat is not None]\n",
    "corr_df = pd.DataFrame(use_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872ad68-3dbe-44e5-a185-51e0d1ea4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"ave_corr\"] = corr_df[\"ave_corr\"].apply(lambda x: x[use_height][:,use_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c80d5d-41e2-46d4-8601-934a9737560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71014c4-7704-452b-8c4c-fb3587869840",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = clean_df(\n",
    "    corr_df,\n",
    "    exp_types=config[\"aliases\"],\n",
    "    subject_typos=config[\"typos\"][\"subject\"],\n",
    "    chk_fields=config[\"parse_metadata\"][\"chk_fields\"],\n",
    "    exclude_subjects=config[\"exclusions\"][\"subjects\"],\n",
    "    exclude_dates=config[\"exclusions\"][\"dates\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de16ce3-a220-4e70-a657-8ddafb37512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12042985-f445-414d-9ba0-47e4e29ab991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f5275-d794-4721-9836-c31ff0f3e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df[\"distortion_coeffs\"] = pa.array(corr_df[\"distortion_coeffs\"].apply(lambda x: x.squeeze()))\n",
    "corr_df[\"ave_corr\"] = pa.array(corr_df[\"ave_corr\"].apply(list))\n",
    "corr_df[\"intrinsic_matrix\"] = pa.array(corr_df[\"intrinsic_matrix\"].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153e07c-336a-48ff-8f32-1450d97e1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config[\"dirs\"][\"analysis\"], exist_ok=True)\n",
    "corr_df.to_parquet(os.path.join(config[\"dirs\"][\"analysis\"], \"fluorescence_autocorrelation.parquet\"), engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883e08f-111b-4d3d-ae2c-58cff3710b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to apply vstack when you load in..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_analysis]",
   "language": "python",
   "name": "conda-env-data_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
